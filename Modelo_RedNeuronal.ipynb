{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0  ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "0  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...          0          0          0         0       689         0   \n",
       "1  ...       3272       3455       3261         0      1000      1000   \n",
       "2  ...      14331      14948      15549      1518      1500      1000   \n",
       "3  ...      28314      28959      29547      2000      2019      1200   \n",
       "4  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "0  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#% pip install xlrd\n",
    "\n",
    "# Especifica la ruta de tu archivo Excel\n",
    "ruta_excel = \"C:/Users/jpcan/OneDrive/Documentos/Andes Universidad/Analitica computacional/Proyecto 2/Copia de default of credit card clients.xls\"\n",
    "\n",
    "# Lee el archivo Excel en un DataFrame de pandas\n",
    "datos_excel = pd.read_excel(ruta_excel, sheet_name=\"Data\")\n",
    "\n",
    "datos_excel.columns = datos_excel.iloc[0]\n",
    "\n",
    "# Elimina la primera fila, ya que ahora son los nombres de las columnas\n",
    "datos_excel = datos_excel[1:]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'df' es tu DataFrame\n",
    "# df = pd.read_excel(\"ruta/a/tu/archivo.xlsx\")\n",
    "\n",
    "# Verifica si hay valores faltantes en cada columna\n",
    "valores_faltantes_por_columna = datos_excel.isna().sum()\n",
    "\n",
    "# También puedes usar df.isnull().sum() para el mismo propósito\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'datos_excel' es tu DataFrame\n",
    "# datos_excel = pd.read_excel(\"ruta/a/tu/archivo.xlsx\")\n",
    "\n",
    "# Eliminar filas con valores atípicos en la columna \"EDUCATION\"\n",
    "datos_excel = datos_excel[datos_excel['EDUCATION'].isin([1, 2, 3, 4])]\n",
    "\n",
    "# Eliminar filas con valores atípicos en la columna \"MARRIAGE\"\n",
    "datos_excel = datos_excel[datos_excel['MARRIAGE'].isin([1, 2, 3])]\n",
    "\n",
    "# Reindexar el DataFrame si es necesario\n",
    "datos_excel.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Cambiar el nombre de la columna \"PAY_0\" a \"PAY_1\"\n",
    "datos_excel = datos_excel.rename(columns={\"PAY_0\": \"PAY_1\"})\n",
    "\n",
    "# Convertir todas las columnas a tipos de datos numéricos\n",
    "datos_excel = datos_excel.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "datos_excel.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "#import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29601, 24)\n",
      "(29601,)\n"
     ]
    }
   ],
   "source": [
    "# split into X and Y\n",
    "Y = datos_excel['default payment next month']\n",
    "X = datos_excel.drop(['default payment next month'], axis=1)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# convert to numpy arrays\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18062 150000      1      2      1     31      0      0     -1     -1\n",
      "       0      0  64276  64226   4254 145578 148012 126848   3500   4508\n",
      "  145578   5115  10000   7598]\n",
      " [ 12085  60000      1      1      2     27      0      0      0      0\n",
      "       0      2  21387  22416  23444  26038  28607  27997   1378   1406\n",
      "    3000   3000      0    923]\n",
      " [ 11593 260000      2      1      2     27     -1     -1     -1     -1\n",
      "       0     -1    399    399    399    798    399    399    399    399\n",
      "     798      0    399    399]]\n",
      "[[ 0.35620325 -0.13554575 -1.23717033  0.25316363 -1.06975026 -0.48887123\n",
      "   0.00830747  0.1028126  -0.69989757 -0.66575939  0.22336415  0.24280027\n",
      "   0.1767551   0.21388414 -0.6142591   1.58598146  1.76754819  1.47967336\n",
      "  -0.12992872 -0.06039584  7.80872378  0.01615083  0.34452676  0.14494164]\n",
      " [-0.33253274 -0.82883215 -1.23717033 -1.15450643  0.86120247 -0.92366825\n",
      "   0.00830747  0.1028126   0.1281084   0.18348618  0.22336415  1.97100179\n",
      "  -0.4066762  -0.37597319 -0.33797882 -0.26844981 -0.1951484  -0.18371602\n",
      "  -0.2649766  -0.19645011 -0.12859693 -0.12228574 -0.31451175 -0.24983672]\n",
      " [-0.38922642  0.71180429  0.80829614 -1.15450643  0.86120247 -0.92366825\n",
      "  -0.87583114 -0.72917452 -0.69989757 -0.66575939  0.22336415 -0.62130049\n",
      "  -0.69218195 -0.68659001 -0.66975991 -0.65999947 -0.65881194 -0.64811416\n",
      "  -0.32728191 -0.24061731 -0.25118232 -0.31864968 -0.28821612 -0.28082756]]\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos (opcional, pero es común en redes neuronales)\n",
    "std_scl = StandardScaler()\n",
    "std_scl.fit(X_train)\n",
    "\n",
    "print(X_train[0:3,])\n",
    "X_train = std_scl.transform(X_train)\n",
    "print(X_train[0:3,])\n",
    "X_valid = std_scl.transform(X_valid)\n",
    "X_test = std_scl.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                1600      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3713 (14.50 KB)\n",
      "Trainable params: 3713 (14.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.InputLayer(input_shape=(24,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[0]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08813706, -0.2636089 ,  0.1825119 , -0.00305492, -0.17238706,\n",
       "        -0.26064277, -0.25012302,  0.10656729, -0.17226675, -0.16254736,\n",
       "         0.01563627, -0.2362585 , -0.10438813, -0.1767099 , -0.18801293,\n",
       "        -0.11694467,  0.09348616,  0.136184  , -0.06484352, -0.03931451,\n",
       "        -0.18672603,  0.10122499, -0.10440676, -0.22930497,  0.10183689,\n",
       "         0.11778006, -0.04746386,  0.20467013,  0.01819572, -0.11036216,\n",
       "        -0.08593625, -0.16442978, -0.08668503, -0.2541436 , -0.18666172,\n",
       "         0.21614617, -0.2887984 ,  0.08934784, -0.14401397, -0.02600083,\n",
       "        -0.08619651,  0.22523564, -0.07596877,  0.05167368,  0.25418484,\n",
       "        -0.054766  , -0.26704448, -0.2684912 , -0.2628836 ,  0.23198646,\n",
       "         0.01163778, -0.1215158 ,  0.2895074 ,  0.18927452,  0.2860852 ,\n",
       "         0.29526645, -0.08588596,  0.24282545,  0.29438603,  0.07444873,\n",
       "        -0.10503253, -0.1733979 ,  0.24615782, -0.23683329],\n",
       "       [ 0.09223759,  0.26686752, -0.16195622,  0.07405901,  0.15081134,\n",
       "         0.10488918, -0.1424921 , -0.02971503,  0.17802528,  0.2326765 ,\n",
       "         0.18097284, -0.02600351, -0.00493947,  0.23325747, -0.0193761 ,\n",
       "        -0.14272206,  0.03841218,  0.18408003,  0.10750362,  0.20779735,\n",
       "         0.21579081, -0.26957938, -0.09768188,  0.24333829, -0.09113945,\n",
       "         0.03512773, -0.1648654 , -0.12122388,  0.00458133, -0.13400443,\n",
       "        -0.25644138,  0.0488458 ,  0.07027775,  0.19667411, -0.23042485,\n",
       "         0.07375875, -0.17714596,  0.10985792,  0.08827871,  0.07237831,\n",
       "        -0.11153622,  0.25951147, -0.1077721 , -0.01167729,  0.05234575,\n",
       "         0.07822683, -0.10315089, -0.16434473, -0.14293557, -0.03210679,\n",
       "        -0.21466593,  0.04393536, -0.06708713, -0.08691131,  0.05411524,\n",
       "         0.21935654, -0.15141141,  0.15552717, -0.12289999,  0.00034985,\n",
       "         0.28485507, -0.18732241, -0.08379434,  0.00912705],\n",
       "       [ 0.01848233, -0.11832865,  0.12375027,  0.03451341, -0.11934103,\n",
       "        -0.2540278 ,  0.27188373,  0.1474565 , -0.23149276,  0.0595054 ,\n",
       "         0.00621879,  0.00186032, -0.00782338, -0.03076699,  0.08336857,\n",
       "         0.16285905,  0.17873737,  0.11199358, -0.01490155,  0.27691662,\n",
       "         0.00170919,  0.08762094,  0.05171537, -0.28132835, -0.09784172,\n",
       "        -0.04155543,  0.152302  , -0.2924077 , -0.2548145 ,  0.12526372,\n",
       "         0.15935984,  0.1840888 ,  0.01515239, -0.21353698,  0.18215668,\n",
       "         0.11814049,  0.10102391, -0.06133151, -0.29004568, -0.2785487 ,\n",
       "        -0.10034008, -0.26771984, -0.2333292 , -0.20695645,  0.10546872,\n",
       "        -0.06658125, -0.21699041,  0.2887497 , -0.03674895, -0.10122931,\n",
       "        -0.01081681, -0.01938552, -0.10495137,  0.03438431, -0.12330778,\n",
       "        -0.04227263,  0.0743576 , -0.10636219,  0.14613369, -0.07173567,\n",
       "        -0.02932701, -0.02796865,  0.23041439,  0.26310432],\n",
       "       [-0.2707958 ,  0.1548383 ,  0.2870832 ,  0.22508568,  0.29441434,\n",
       "         0.1527687 , -0.14550467, -0.25411534, -0.14913163,  0.03196451,\n",
       "         0.21175057,  0.05334023,  0.06584945,  0.10611793, -0.27743822,\n",
       "         0.06489593,  0.11508256, -0.04642451, -0.03163201, -0.19595951,\n",
       "        -0.09866673,  0.09594819,  0.06319225, -0.20949636,  0.17226583,\n",
       "        -0.2641965 , -0.29561242,  0.17368728, -0.28896844, -0.0108237 ,\n",
       "         0.00622508,  0.06780022, -0.22300184,  0.11257169,  0.15056708,\n",
       "         0.15709218, -0.22419856,  0.2964248 ,  0.17255422,  0.02013975,\n",
       "        -0.2884605 , -0.13809681,  0.01240301,  0.20314807, -0.2211874 ,\n",
       "         0.14494675,  0.21117711,  0.2882293 , -0.04645169,  0.01855287,\n",
       "         0.16029158, -0.22298342, -0.16257024,  0.05160582,  0.12349403,\n",
       "         0.08342868, -0.10438912,  0.1892302 ,  0.1067692 , -0.27633137,\n",
       "        -0.28615195,  0.09464219,  0.28212607, -0.19483559]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_function() missing 1 required positional argument: 'steps_per_execution'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jpcan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jpcan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_function() missing 1 required positional argument: 'steps_per_execution'\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "# Learning curve(Loss)\n",
    "# let's see the training and validation loss by epoch\n",
    "\n",
    "# loss\n",
    "loss_values = history_dict['loss'] # you can change this\n",
    "val_loss_values = history_dict['val_loss'] # you can also change this\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(loss_values) + 1) \n",
    "\n",
    "# plot\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve(accuracy)\n",
    "# let's see the training and validation accuracy by epoch\n",
    "\n",
    "# accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "# range of X (no. of epochs)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plot\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "# orange is for \"orange\"\n",
    "plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# this is the max value - should correspond to\n",
    "# the HIGHEST train accuracy\n",
    "np.max(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# see how these are numbers between 0 and 1? \n",
    "model.predict(X) # prob of successes (survival)\n",
    "np.round(model.predict(X),0) # 1 and 0 (survival or not)\n",
    "Y # 1 and 0 (survival or not)\n",
    "\n",
    "# so we need to round to a whole number (0 or 1),\n",
    "# or the confusion matrix won't work!\n",
    "preds = np.round(model.predict(X),0)\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(Y, preds)) # order matters! (actual, predicted)\n",
    "\n",
    "## array([[490,  59],   ([[TN, FP],\n",
    "##       [105, 235]])     [Fn, TP]])\n",
    "\n",
    "print(classification_report(Y, preds))\n",
    "##               precision    recall  f1-score   support\n",
    "## \n",
    "##            0       0.82      0.89      0.86       549\n",
    "##            1       0.80      0.69      0.74       340\n",
    "## \n",
    "##     accuracy                           0.82       889\n",
    "##    macro avg       0.81      0.79      0.80       889\n",
    "## weighted avg       0.81      0.82      0.81       889"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jpcan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_function() missing 1 required positional argument: 'steps_per_execution'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[1;32mc:\\Users\\jpcan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jpcan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__train_function() missing 1 required positional argument: 'steps_per_execution'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Definir el modelo de red neuronal\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train.shape[1],), activation='relu'),  # Capa de entrada con 64 neuronas y activación ReLU\n",
    "    Dense(32, activation='relu'),  # Segunda capa con 32 neuronas y activación ReLU\n",
    "    Dense(1, activation='sigmoid')  # Capa de salida con 1 neurona y activación Sigmoide para clasificación binaria\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Configurar EarlyStopping para evitar el sobreajuste\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
