{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "17W9PiJJ0qMRAy_u99H2siyLrRq72X3vn",
      "authorship_tag": "ABX9TyNhutbVNkqZ4anHKYyWqItl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juanxtron/Proyecto-2/blob/main/Proyecto_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9Bc-JXislj9G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#% pip install xlrd\n",
        "\n",
        "# Especifica la ruta de tu archivo Excel\n",
        "ruta_excel = '/content/drive/MyDrive/Copia de default of credit card clients.xls'\n",
        "\n",
        "# Lee el archivo Excel en un DataFrame de pandas\n",
        "datos_excel = pd.read_excel(ruta_excel, sheet_name=\"Data\")\n",
        "\n",
        "datos_excel.columns = datos_excel.iloc[0]\n",
        "\n",
        "# Elimina la primera fila, ya que ahora son los nombres de las columnas\n",
        "datos_excel = datos_excel[1:]\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Supongamos que 'df' es tu DataFrame\n",
        "# df = pd.read_excel(\"ruta/a/tu/archivo.xlsx\")\n",
        "\n",
        "# Verifica si hay valores faltantes en cada columna\n",
        "valores_faltantes_por_columna = datos_excel.isna().sum()\n",
        "\n",
        "# También puedes usar df.isnull().sum() para el mismo propósito\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Supongamos que 'datos_excel' es tu DataFrame\n",
        "# datos_excel = pd.read_excel(\"ruta/a/tu/archivo.xlsx\")\n",
        "\n",
        "# Eliminar filas con valores atípicos en la columna \"EDUCATION\"\n",
        "datos_excel = datos_excel[datos_excel['EDUCATION'].isin([1, 2, 3, 4])]\n",
        "\n",
        "# Eliminar filas con valores atípicos en la columna \"MARRIAGE\"\n",
        "datos_excel = datos_excel[datos_excel['MARRIAGE'].isin([1, 2, 3])]\n",
        "\n",
        "# Reindexar el DataFrame si es necesario\n",
        "datos_excel.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Cambiar el nombre de la columna \"PAY_0\" a \"PAY_1\"\n",
        "datos_excel = datos_excel.rename(columns={\"PAY_0\": \"PAY_1\"})\n",
        "\n",
        "# Convertir todas las columnas a tipos de datos numéricos\n",
        "datos_excel = datos_excel.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "datos_excel.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "K6zxD_pW_Vad",
        "outputId": "fe201873-b349-4815-c10b-a1de6aea4bbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0  ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
              "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
              "1   2     120000    2          2         2   26     -1      2      0      0   \n",
              "2   3      90000    2          2         2   34      0      0      0      0   \n",
              "3   4      50000    2          2         1   37      0      0      0      0   \n",
              "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
              "\n",
              "0  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
              "0  ...          0          0          0         0       689         0   \n",
              "1  ...       3272       3455       3261         0      1000      1000   \n",
              "2  ...      14331      14948      15549      1518      1500      1000   \n",
              "3  ...      28314      28959      29547      2000      2019      1200   \n",
              "4  ...      20940      19146      19131      2000     36681     10000   \n",
              "\n",
              "0  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
              "0         0         0         0                           1  \n",
              "1      1000         0      2000                           1  \n",
              "2      1000      1000      5000                           0  \n",
              "3      1100      1069      1000                           0  \n",
              "4      9000       689       679                           0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a82e869-8e56-42ee-baee-c8d17a1c468b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_1</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>...</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default payment next month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3272</td>\n",
              "      <td>3455</td>\n",
              "      <td>3261</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>14331</td>\n",
              "      <td>14948</td>\n",
              "      <td>15549</td>\n",
              "      <td>1518</td>\n",
              "      <td>1500</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>1000</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>28314</td>\n",
              "      <td>28959</td>\n",
              "      <td>29547</td>\n",
              "      <td>2000</td>\n",
              "      <td>2019</td>\n",
              "      <td>1200</td>\n",
              "      <td>1100</td>\n",
              "      <td>1069</td>\n",
              "      <td>1000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20940</td>\n",
              "      <td>19146</td>\n",
              "      <td>19131</td>\n",
              "      <td>2000</td>\n",
              "      <td>36681</td>\n",
              "      <td>10000</td>\n",
              "      <td>9000</td>\n",
              "      <td>689</td>\n",
              "      <td>679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a82e869-8e56-42ee-baee-c8d17a1c468b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9a82e869-8e56-42ee-baee-c8d17a1c468b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9a82e869-8e56-42ee-baee-c8d17a1c468b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a03c2db0-ec9e-460c-bcbd-ca0474cff8aa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a03c2db0-ec9e-460c-bcbd-ca0474cff8aa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a03c2db0-ec9e-460c-bcbd-ca0474cff8aa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "datos_excel"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar las librerías necesarias\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "#import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "tgJ3F_jO4x_V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split into X and Y\n",
        "Y = datos_excel['default payment next month']\n",
        "X = datos_excel.drop(['default payment next month'], axis=1)\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "# convert to numpy arrays\n",
        "X = np.array(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzuSdZoSlofv",
        "outputId": "1c9b03ed-c6ea-4fbd-a556-d011e25ea20e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29601, 24)\n",
            "(29601,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar los datos (opcional, pero es común en redes neuronales)\n",
        "std_scl = StandardScaler()\n",
        "std_scl.fit(X_train)\n",
        "\n",
        "print(X_train[0:3,])\n",
        "X_train = std_scl.transform(X_train)\n",
        "print(X_train[0:3,])\n",
        "X_valid = std_scl.transform(X_valid)\n",
        "X_test = std_scl.transform(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqxAoRHTCGJP",
        "outputId": "04568d7f-ece0-4556-fdcf-3ae414eb5133"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 18062 150000      1      2      1     31      0      0     -1     -1\n",
            "       0      0  64276  64226   4254 145578 148012 126848   3500   4508\n",
            "  145578   5115  10000   7598]\n",
            " [ 12085  60000      1      1      2     27      0      0      0      0\n",
            "       0      2  21387  22416  23444  26038  28607  27997   1378   1406\n",
            "    3000   3000      0    923]\n",
            " [ 11593 260000      2      1      2     27     -1     -1     -1     -1\n",
            "       0     -1    399    399    399    798    399    399    399    399\n",
            "     798      0    399    399]]\n",
            "[[ 0.35620325 -0.13554575 -1.23717033  0.25316363 -1.06975026 -0.48887123\n",
            "   0.00830747  0.1028126  -0.69989757 -0.66575939  0.22336415  0.24280027\n",
            "   0.1767551   0.21388414 -0.6142591   1.58598146  1.76754819  1.47967336\n",
            "  -0.12992872 -0.06039584  7.80872378  0.01615083  0.34452676  0.14494164]\n",
            " [-0.33253274 -0.82883215 -1.23717033 -1.15450643  0.86120247 -0.92366825\n",
            "   0.00830747  0.1028126   0.1281084   0.18348618  0.22336415  1.97100179\n",
            "  -0.4066762  -0.37597319 -0.33797882 -0.26844981 -0.1951484  -0.18371602\n",
            "  -0.2649766  -0.19645011 -0.12859693 -0.12228574 -0.31451175 -0.24983672]\n",
            " [-0.38922642  0.71180429  0.80829614 -1.15450643  0.86120247 -0.92366825\n",
            "  -0.87583114 -0.72917452 -0.69989757 -0.66575939  0.22336415 -0.62130049\n",
            "  -0.69218195 -0.68659001 -0.66975991 -0.65999947 -0.65881194 -0.64811416\n",
            "  -0.32728191 -0.24061731 -0.25118232 -0.31864968 -0.28821612 -0.28082756]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.InputLayer(input_shape=(24,)))\n",
        "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7klovgNGCIt3",
        "outputId": "797de77b-3d87-4772-b489-bcc60ebe2f45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1600      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3713 (14.50 KB)\n",
            "Trainable params: 3713 (14.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden1 = model.layers[0]\n",
        "hidden1.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b-8G--p6CMBL",
        "outputId": "fa850eef-e367-4f01-8313-4e340d90ab19"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dense'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, biases = hidden1.get_weights()\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97xs0ceCOvf",
        "outputId": "45787e8a-0748-40b2-ac78-731b25ca4011"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.05297968e-01,  2.12724030e-01, -7.30099529e-02,\n",
              "        -1.36328414e-01, -3.17699015e-02, -2.53348351e-02,\n",
              "        -9.77819562e-02,  2.11301148e-02, -2.50984371e-01,\n",
              "         1.16739631e-01, -1.02909252e-01, -2.11066961e-01,\n",
              "         5.79770207e-02, -1.60704032e-01, -5.05200773e-02,\n",
              "        -1.12471700e-01,  2.33256102e-01,  2.80859590e-01,\n",
              "        -6.85730875e-02,  4.19139862e-03, -2.61834830e-01,\n",
              "        -2.26544797e-01, -2.06838384e-01,  2.96433687e-01,\n",
              "        -1.87876940e-01,  2.11214960e-01,  2.82794237e-03,\n",
              "        -6.60234690e-02,  1.97563052e-01,  9.58066285e-02,\n",
              "         5.24219573e-02,  2.59135127e-01, -2.46748075e-01,\n",
              "         1.15650475e-01, -3.20363045e-02,  2.60993361e-01,\n",
              "        -1.32056847e-01,  1.76350057e-01, -1.92633554e-01,\n",
              "         8.02133381e-02,  4.13395464e-02,  1.32241279e-01,\n",
              "        -1.40539423e-01, -6.46588206e-03, -8.55799466e-02,\n",
              "        -1.20112270e-01,  7.34046996e-02, -2.86771297e-01,\n",
              "         1.81345850e-01,  2.75016785e-01,  2.63893306e-02,\n",
              "        -1.18039921e-01, -1.66553631e-01, -2.36322105e-01,\n",
              "        -1.74564108e-01,  2.11852014e-01,  1.44702703e-01,\n",
              "        -8.34895968e-02, -9.44420397e-02,  2.79701352e-01,\n",
              "        -9.37868804e-02,  1.30806237e-01,  5.48966527e-02,\n",
              "         1.11141890e-01],\n",
              "       [ 2.23618448e-01,  5.42491376e-02,  6.39114380e-02,\n",
              "        -9.22783911e-02,  6.51312768e-02, -1.42157972e-02,\n",
              "        -2.49980405e-01,  1.31526560e-01, -1.55370593e-01,\n",
              "         1.15308464e-02,  1.11589253e-01,  9.67368484e-02,\n",
              "        -2.64873832e-01, -7.96020031e-03, -6.16157204e-02,\n",
              "        -4.83596772e-02, -2.90644616e-01,  7.05946088e-02,\n",
              "        -2.56819874e-01, -1.38563097e-01, -1.86216831e-03,\n",
              "         1.14392936e-01,  1.68099642e-01, -2.17132270e-01,\n",
              "         2.78321743e-01, -1.64054438e-01,  2.09145784e-01,\n",
              "         2.08500504e-01, -1.91250145e-01,  6.91822171e-03,\n",
              "        -1.70348629e-01,  1.27604425e-01,  1.69108152e-01,\n",
              "         1.51146770e-01, -1.21642575e-01,  3.91273201e-02,\n",
              "        -1.37399152e-01,  7.38870502e-02, -2.82218128e-01,\n",
              "        -7.50539154e-02, -1.48718461e-01,  2.52645493e-01,\n",
              "        -6.16730899e-02, -2.36462265e-01,  1.92388237e-01,\n",
              "        -1.99255943e-02, -2.68331230e-01,  1.43815607e-01,\n",
              "        -2.01382697e-01, -2.01344490e-03,  1.09408468e-01,\n",
              "        -1.61605656e-01, -2.32126117e-01, -1.79335028e-01,\n",
              "        -1.69051275e-01, -4.72906381e-02,  2.49440908e-01,\n",
              "        -4.48101461e-02, -2.01586455e-01, -5.51861078e-02,\n",
              "        -1.04160607e-02,  1.32257998e-01, -1.70454308e-01,\n",
              "        -2.52744555e-01],\n",
              "       [-1.69512242e-01, -2.24585667e-01,  1.24842614e-01,\n",
              "         2.10939288e-01,  2.54202247e-01,  2.51210034e-02,\n",
              "         5.51638007e-03,  2.79234052e-02,  1.74993843e-01,\n",
              "         2.87984848e-01,  2.35433519e-01, -1.37718841e-01,\n",
              "        -2.16604859e-01, -1.37855709e-02,  2.65318155e-01,\n",
              "        -1.01457417e-01,  1.51449382e-01,  1.15363598e-02,\n",
              "        -1.10670641e-01,  1.01705283e-01,  2.28488564e-01,\n",
              "         7.05331266e-02, -1.36956587e-01, -1.90439165e-01,\n",
              "         6.94080591e-02, -1.18232623e-01,  4.07038629e-02,\n",
              "         8.95489454e-02,  2.82808840e-01,  1.96126103e-01,\n",
              "        -2.96895832e-01,  3.57175171e-02, -2.77237236e-01,\n",
              "        -1.71602666e-01, -2.84194946e-04,  8.41810107e-02,\n",
              "        -2.55026460e-01,  1.15292341e-01, -1.27902627e-03,\n",
              "        -1.31610677e-01, -2.12383091e-01,  2.90860951e-01,\n",
              "         6.64767623e-03,  1.39516771e-01, -1.18981406e-01,\n",
              "        -4.44210470e-02, -6.69332296e-02,  1.25431418e-01,\n",
              "        -2.13996246e-01,  2.47874200e-01, -2.84940362e-01,\n",
              "         2.14003325e-01,  2.59955943e-01, -1.76376626e-01,\n",
              "         1.29158646e-01, -2.31511101e-01,  1.19208395e-01,\n",
              "        -6.17084950e-02, -2.52940863e-01,  1.83884561e-01,\n",
              "         4.14955914e-02, -1.37258783e-01, -1.84289306e-01,\n",
              "        -1.20593011e-02],\n",
              "       [ 4.88899052e-02,  1.86018944e-02, -2.39699841e-01,\n",
              "        -1.18996069e-01, -2.43515164e-01,  2.18317389e-01,\n",
              "        -1.84066564e-01, -1.06900647e-01,  1.15151197e-01,\n",
              "         2.19713271e-01, -5.37473708e-02, -7.56277740e-02,\n",
              "         7.47784972e-02,  2.89371908e-01,  4.53734398e-02,\n",
              "        -2.46797293e-01, -8.36092085e-02, -2.78612018e-01,\n",
              "        -3.75213325e-02, -1.30993128e-02, -2.42645621e-01,\n",
              "        -2.55752295e-01, -1.47657275e-01,  2.18254328e-01,\n",
              "        -2.67105609e-01, -1.55425340e-01, -1.04872972e-01,\n",
              "        -1.42347828e-01, -1.44557163e-01, -4.54291701e-02,\n",
              "        -2.13022679e-01, -1.14142567e-01,  2.82162488e-01,\n",
              "        -2.25330144e-01, -1.69627607e-01,  2.42947042e-01,\n",
              "        -7.96634257e-02, -2.14009553e-01, -2.66628981e-01,\n",
              "        -1.19886220e-01,  2.85689712e-01, -5.97748011e-02,\n",
              "        -2.60589600e-01,  1.99065924e-01, -2.35764459e-01,\n",
              "        -2.53870964e-01,  2.09047794e-01,  2.51861811e-02,\n",
              "         4.26328182e-02,  7.99300075e-02,  1.35875583e-01,\n",
              "         2.40336895e-01,  7.29280710e-02,  9.32194591e-02,\n",
              "         1.58718795e-01, -2.05454260e-01, -2.24963784e-01,\n",
              "         1.96653694e-01, -2.23533630e-01,  2.30838716e-01,\n",
              "        -2.51238614e-01, -1.77269042e-01, -2.41171494e-01,\n",
              "         1.56883240e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "BmhUrJGdCQuZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000,\n",
        "                    validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALgHccekCUAk",
        "outputId": "767354bc-daba-4451-cca5-d662206362d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.4029 - accuracy: 0.8304 - val_loss: 0.4393 - val_accuracy: 0.8203\n",
            "Epoch 2/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.4013 - accuracy: 0.8297 - val_loss: 0.4450 - val_accuracy: 0.8144\n",
            "Epoch 3/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8320 - val_loss: 0.4475 - val_accuracy: 0.8104\n",
            "Epoch 4/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8312 - val_loss: 0.4459 - val_accuracy: 0.8190\n",
            "Epoch 5/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3981 - accuracy: 0.8318 - val_loss: 0.4420 - val_accuracy: 0.8180\n",
            "Epoch 6/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8335 - val_loss: 0.4469 - val_accuracy: 0.8222\n",
            "Epoch 7/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8335 - val_loss: 0.4460 - val_accuracy: 0.8184\n",
            "Epoch 8/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.8337 - val_loss: 0.4494 - val_accuracy: 0.8184\n",
            "Epoch 9/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3943 - accuracy: 0.8328 - val_loss: 0.4463 - val_accuracy: 0.8195\n",
            "Epoch 10/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3942 - accuracy: 0.8347 - val_loss: 0.4495 - val_accuracy: 0.8190\n",
            "Epoch 11/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3920 - accuracy: 0.8332 - val_loss: 0.4524 - val_accuracy: 0.8106\n",
            "Epoch 12/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3908 - accuracy: 0.8346 - val_loss: 0.4539 - val_accuracy: 0.8136\n",
            "Epoch 13/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8342 - val_loss: 0.4483 - val_accuracy: 0.8171\n",
            "Epoch 14/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3892 - accuracy: 0.8368 - val_loss: 0.4550 - val_accuracy: 0.8193\n",
            "Epoch 15/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.8363 - val_loss: 0.4540 - val_accuracy: 0.8169\n",
            "Epoch 16/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3869 - accuracy: 0.8369 - val_loss: 0.4552 - val_accuracy: 0.8136\n",
            "Epoch 17/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3861 - accuracy: 0.8361 - val_loss: 0.4564 - val_accuracy: 0.8089\n",
            "Epoch 18/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3848 - accuracy: 0.8384 - val_loss: 0.4555 - val_accuracy: 0.8176\n",
            "Epoch 19/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3844 - accuracy: 0.8383 - val_loss: 0.4632 - val_accuracy: 0.8068\n",
            "Epoch 20/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3834 - accuracy: 0.8384 - val_loss: 0.4579 - val_accuracy: 0.8095\n",
            "Epoch 21/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3827 - accuracy: 0.8379 - val_loss: 0.4609 - val_accuracy: 0.8182\n",
            "Epoch 22/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3817 - accuracy: 0.8383 - val_loss: 0.4579 - val_accuracy: 0.8112\n",
            "Epoch 23/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3812 - accuracy: 0.8404 - val_loss: 0.4602 - val_accuracy: 0.8152\n",
            "Epoch 24/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3800 - accuracy: 0.8402 - val_loss: 0.4633 - val_accuracy: 0.8144\n",
            "Epoch 25/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8375 - val_loss: 0.4677 - val_accuracy: 0.8123\n",
            "Epoch 26/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3779 - accuracy: 0.8417 - val_loss: 0.4627 - val_accuracy: 0.8127\n",
            "Epoch 27/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3770 - accuracy: 0.8409 - val_loss: 0.4612 - val_accuracy: 0.8150\n",
            "Epoch 28/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8416 - val_loss: 0.4627 - val_accuracy: 0.8117\n",
            "Epoch 29/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3763 - accuracy: 0.8403 - val_loss: 0.4716 - val_accuracy: 0.8140\n",
            "Epoch 30/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3756 - accuracy: 0.8416 - val_loss: 0.4745 - val_accuracy: 0.8081\n",
            "Epoch 31/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3735 - accuracy: 0.8424 - val_loss: 0.4684 - val_accuracy: 0.8140\n",
            "Epoch 32/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3728 - accuracy: 0.8432 - val_loss: 0.4709 - val_accuracy: 0.8169\n",
            "Epoch 33/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3717 - accuracy: 0.8436 - val_loss: 0.4704 - val_accuracy: 0.8093\n",
            "Epoch 34/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8430 - val_loss: 0.4715 - val_accuracy: 0.8110\n",
            "Epoch 35/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3707 - accuracy: 0.8429 - val_loss: 0.4809 - val_accuracy: 0.8085\n",
            "Epoch 36/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3703 - accuracy: 0.8425 - val_loss: 0.4759 - val_accuracy: 0.8038\n",
            "Epoch 37/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3695 - accuracy: 0.8428 - val_loss: 0.4775 - val_accuracy: 0.8074\n",
            "Epoch 38/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3680 - accuracy: 0.8442 - val_loss: 0.4746 - val_accuracy: 0.8104\n",
            "Epoch 39/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3688 - accuracy: 0.8419 - val_loss: 0.4783 - val_accuracy: 0.8091\n",
            "Epoch 40/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3683 - accuracy: 0.8441 - val_loss: 0.4802 - val_accuracy: 0.8064\n",
            "Epoch 41/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3669 - accuracy: 0.8438 - val_loss: 0.4764 - val_accuracy: 0.8074\n",
            "Epoch 42/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8451 - val_loss: 0.4804 - val_accuracy: 0.8060\n",
            "Epoch 43/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3657 - accuracy: 0.8452 - val_loss: 0.4813 - val_accuracy: 0.8070\n",
            "Epoch 44/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8452 - val_loss: 0.4803 - val_accuracy: 0.8095\n",
            "Epoch 45/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8461 - val_loss: 0.4880 - val_accuracy: 0.8030\n",
            "Epoch 46/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8459 - val_loss: 0.4848 - val_accuracy: 0.8032\n",
            "Epoch 47/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8450 - val_loss: 0.4901 - val_accuracy: 0.8045\n",
            "Epoch 48/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8453 - val_loss: 0.4820 - val_accuracy: 0.8076\n",
            "Epoch 49/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3618 - accuracy: 0.8452 - val_loss: 0.4856 - val_accuracy: 0.8055\n",
            "Epoch 50/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3591 - accuracy: 0.8475 - val_loss: 0.4896 - val_accuracy: 0.8041\n",
            "Epoch 51/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3607 - accuracy: 0.8467 - val_loss: 0.4876 - val_accuracy: 0.8022\n",
            "Epoch 52/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3593 - accuracy: 0.8487 - val_loss: 0.4896 - val_accuracy: 0.8121\n",
            "Epoch 53/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8465 - val_loss: 0.4952 - val_accuracy: 0.8085\n",
            "Epoch 54/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8469 - val_loss: 0.4953 - val_accuracy: 0.8060\n",
            "Epoch 55/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3577 - accuracy: 0.8488 - val_loss: 0.4949 - val_accuracy: 0.8098\n",
            "Epoch 56/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3583 - accuracy: 0.8486 - val_loss: 0.4925 - val_accuracy: 0.8028\n",
            "Epoch 57/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3568 - accuracy: 0.8489 - val_loss: 0.4897 - val_accuracy: 0.8083\n",
            "Epoch 58/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3572 - accuracy: 0.8476 - val_loss: 0.4919 - val_accuracy: 0.8053\n",
            "Epoch 59/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8497 - val_loss: 0.5025 - val_accuracy: 0.7952\n",
            "Epoch 60/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3547 - accuracy: 0.8495 - val_loss: 0.4953 - val_accuracy: 0.8043\n",
            "Epoch 61/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3535 - accuracy: 0.8500 - val_loss: 0.5005 - val_accuracy: 0.7975\n",
            "Epoch 62/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8517 - val_loss: 0.5047 - val_accuracy: 0.8005\n",
            "Epoch 63/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3518 - accuracy: 0.8512 - val_loss: 0.5003 - val_accuracy: 0.7984\n",
            "Epoch 64/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3519 - accuracy: 0.8519 - val_loss: 0.5057 - val_accuracy: 0.7996\n",
            "Epoch 65/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3526 - accuracy: 0.8505 - val_loss: 0.5093 - val_accuracy: 0.7971\n",
            "Epoch 66/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3496 - accuracy: 0.8525 - val_loss: 0.5083 - val_accuracy: 0.8015\n",
            "Epoch 67/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3501 - accuracy: 0.8512 - val_loss: 0.5005 - val_accuracy: 0.8068\n",
            "Epoch 68/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3505 - accuracy: 0.8517 - val_loss: 0.5022 - val_accuracy: 0.8114\n",
            "Epoch 69/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3495 - accuracy: 0.8521 - val_loss: 0.5067 - val_accuracy: 0.8003\n",
            "Epoch 70/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3488 - accuracy: 0.8526 - val_loss: 0.5087 - val_accuracy: 0.8043\n",
            "Epoch 71/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3472 - accuracy: 0.8525 - val_loss: 0.5079 - val_accuracy: 0.8003\n",
            "Epoch 72/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3483 - accuracy: 0.8519 - val_loss: 0.5146 - val_accuracy: 0.7939\n",
            "Epoch 73/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8542 - val_loss: 0.5116 - val_accuracy: 0.7975\n",
            "Epoch 74/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3458 - accuracy: 0.8530 - val_loss: 0.5161 - val_accuracy: 0.8011\n",
            "Epoch 75/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8546 - val_loss: 0.5135 - val_accuracy: 0.8032\n",
            "Epoch 76/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8533 - val_loss: 0.5125 - val_accuracy: 0.8051\n",
            "Epoch 77/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3468 - accuracy: 0.8527 - val_loss: 0.5221 - val_accuracy: 0.7965\n",
            "Epoch 78/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3430 - accuracy: 0.8548 - val_loss: 0.5216 - val_accuracy: 0.8009\n",
            "Epoch 79/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8548 - val_loss: 0.5172 - val_accuracy: 0.8043\n",
            "Epoch 80/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3432 - accuracy: 0.8551 - val_loss: 0.5147 - val_accuracy: 0.7967\n",
            "Epoch 81/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3412 - accuracy: 0.8561 - val_loss: 0.5215 - val_accuracy: 0.7975\n",
            "Epoch 82/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3423 - accuracy: 0.8555 - val_loss: 0.5302 - val_accuracy: 0.7990\n",
            "Epoch 83/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8566 - val_loss: 0.5287 - val_accuracy: 0.8060\n",
            "Epoch 84/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8575 - val_loss: 0.5355 - val_accuracy: 0.7916\n",
            "Epoch 85/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3413 - accuracy: 0.8578 - val_loss: 0.5277 - val_accuracy: 0.8030\n",
            "Epoch 86/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8581 - val_loss: 0.5484 - val_accuracy: 0.7943\n",
            "Epoch 87/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8553 - val_loss: 0.5373 - val_accuracy: 0.7857\n",
            "Epoch 88/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8588 - val_loss: 0.5338 - val_accuracy: 0.7971\n",
            "Epoch 89/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3392 - accuracy: 0.8569 - val_loss: 0.5371 - val_accuracy: 0.7965\n",
            "Epoch 90/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3375 - accuracy: 0.8588 - val_loss: 0.5387 - val_accuracy: 0.7886\n",
            "Epoch 91/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3388 - accuracy: 0.8573 - val_loss: 0.5351 - val_accuracy: 0.8024\n",
            "Epoch 92/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.8576 - val_loss: 0.5316 - val_accuracy: 0.8064\n",
            "Epoch 93/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8599 - val_loss: 0.5357 - val_accuracy: 0.8045\n",
            "Epoch 94/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8580 - val_loss: 0.5334 - val_accuracy: 0.8013\n",
            "Epoch 95/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8595 - val_loss: 0.5363 - val_accuracy: 0.8013\n",
            "Epoch 96/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8604 - val_loss: 0.5377 - val_accuracy: 0.8024\n",
            "Epoch 97/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8596 - val_loss: 0.5419 - val_accuracy: 0.7962\n",
            "Epoch 98/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8624 - val_loss: 0.5360 - val_accuracy: 0.8034\n",
            "Epoch 99/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8613 - val_loss: 0.5430 - val_accuracy: 0.7988\n",
            "Epoch 100/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8584 - val_loss: 0.5379 - val_accuracy: 0.8000\n",
            "Epoch 101/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3324 - accuracy: 0.8597 - val_loss: 0.5467 - val_accuracy: 0.7998\n",
            "Epoch 102/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3302 - accuracy: 0.8612 - val_loss: 0.5440 - val_accuracy: 0.7988\n",
            "Epoch 103/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3317 - accuracy: 0.8597 - val_loss: 0.5472 - val_accuracy: 0.8049\n",
            "Epoch 104/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8625 - val_loss: 0.5520 - val_accuracy: 0.7908\n",
            "Epoch 105/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8613 - val_loss: 0.5573 - val_accuracy: 0.7927\n",
            "Epoch 106/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3308 - accuracy: 0.8597 - val_loss: 0.5459 - val_accuracy: 0.8017\n",
            "Epoch 107/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8603 - val_loss: 0.5533 - val_accuracy: 0.7941\n",
            "Epoch 108/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8610 - val_loss: 0.5576 - val_accuracy: 0.7965\n",
            "Epoch 109/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8617 - val_loss: 0.5534 - val_accuracy: 0.7988\n",
            "Epoch 110/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8609 - val_loss: 0.5540 - val_accuracy: 0.7984\n",
            "Epoch 111/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3289 - accuracy: 0.8597 - val_loss: 0.5595 - val_accuracy: 0.8000\n",
            "Epoch 112/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3280 - accuracy: 0.8619 - val_loss: 0.5566 - val_accuracy: 0.7973\n",
            "Epoch 113/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3275 - accuracy: 0.8629 - val_loss: 0.5615 - val_accuracy: 0.7971\n",
            "Epoch 114/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8620 - val_loss: 0.5561 - val_accuracy: 0.7998\n",
            "Epoch 115/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8624 - val_loss: 0.5600 - val_accuracy: 0.7952\n",
            "Epoch 116/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3258 - accuracy: 0.8621 - val_loss: 0.5623 - val_accuracy: 0.7870\n",
            "Epoch 117/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8648 - val_loss: 0.5674 - val_accuracy: 0.7969\n",
            "Epoch 118/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8630 - val_loss: 0.5566 - val_accuracy: 0.7986\n",
            "Epoch 119/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8637 - val_loss: 0.5651 - val_accuracy: 0.7910\n",
            "Epoch 120/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8613 - val_loss: 0.5646 - val_accuracy: 0.7962\n",
            "Epoch 121/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3267 - accuracy: 0.8594 - val_loss: 0.5836 - val_accuracy: 0.7884\n",
            "Epoch 122/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3248 - accuracy: 0.8628 - val_loss: 0.5625 - val_accuracy: 0.7990\n",
            "Epoch 123/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3245 - accuracy: 0.8663 - val_loss: 0.5641 - val_accuracy: 0.8049\n",
            "Epoch 124/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8651 - val_loss: 0.5747 - val_accuracy: 0.7918\n",
            "Epoch 125/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3242 - accuracy: 0.8643 - val_loss: 0.5767 - val_accuracy: 0.7901\n",
            "Epoch 126/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8650 - val_loss: 0.5761 - val_accuracy: 0.7863\n",
            "Epoch 127/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8629 - val_loss: 0.5820 - val_accuracy: 0.7840\n",
            "Epoch 128/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8647 - val_loss: 0.5877 - val_accuracy: 0.7859\n",
            "Epoch 129/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3235 - accuracy: 0.8632 - val_loss: 0.5919 - val_accuracy: 0.7880\n",
            "Epoch 130/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8653 - val_loss: 0.5795 - val_accuracy: 0.7992\n",
            "Epoch 131/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8645 - val_loss: 0.5809 - val_accuracy: 0.7886\n",
            "Epoch 132/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3226 - accuracy: 0.8641 - val_loss: 0.5770 - val_accuracy: 0.7977\n",
            "Epoch 133/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3222 - accuracy: 0.8649 - val_loss: 0.5815 - val_accuracy: 0.7943\n",
            "Epoch 134/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.8656 - val_loss: 0.5760 - val_accuracy: 0.7986\n",
            "Epoch 135/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8662 - val_loss: 0.5705 - val_accuracy: 0.7977\n",
            "Epoch 136/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8664 - val_loss: 0.5882 - val_accuracy: 0.7874\n",
            "Epoch 137/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3208 - accuracy: 0.8668 - val_loss: 0.5715 - val_accuracy: 0.7979\n",
            "Epoch 138/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3217 - accuracy: 0.8656 - val_loss: 0.5829 - val_accuracy: 0.7960\n",
            "Epoch 139/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8681 - val_loss: 0.5778 - val_accuracy: 0.7969\n",
            "Epoch 140/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8637 - val_loss: 0.5877 - val_accuracy: 0.7825\n",
            "Epoch 141/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3201 - accuracy: 0.8650 - val_loss: 0.5799 - val_accuracy: 0.7920\n",
            "Epoch 142/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3179 - accuracy: 0.8660 - val_loss: 0.5752 - val_accuracy: 0.7935\n",
            "Epoch 143/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3198 - accuracy: 0.8656 - val_loss: 0.5825 - val_accuracy: 0.7962\n",
            "Epoch 144/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3190 - accuracy: 0.8672 - val_loss: 0.6010 - val_accuracy: 0.7762\n",
            "Epoch 145/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8669 - val_loss: 0.5897 - val_accuracy: 0.7937\n",
            "Epoch 146/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.8678 - val_loss: 0.5924 - val_accuracy: 0.7823\n",
            "Epoch 147/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8668 - val_loss: 0.5955 - val_accuracy: 0.7861\n",
            "Epoch 148/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8669 - val_loss: 0.5816 - val_accuracy: 0.7948\n",
            "Epoch 149/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8653 - val_loss: 0.5920 - val_accuracy: 0.7865\n",
            "Epoch 150/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8672 - val_loss: 0.5960 - val_accuracy: 0.7880\n",
            "Epoch 151/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8662 - val_loss: 0.5844 - val_accuracy: 0.7931\n",
            "Epoch 152/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3156 - accuracy: 0.8692 - val_loss: 0.5904 - val_accuracy: 0.7931\n",
            "Epoch 153/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3168 - accuracy: 0.8666 - val_loss: 0.5955 - val_accuracy: 0.7948\n",
            "Epoch 154/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3154 - accuracy: 0.8679 - val_loss: 0.5911 - val_accuracy: 0.7884\n",
            "Epoch 155/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8699 - val_loss: 0.5933 - val_accuracy: 0.7884\n",
            "Epoch 156/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.8686 - val_loss: 0.5986 - val_accuracy: 0.7863\n",
            "Epoch 157/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3152 - accuracy: 0.8670 - val_loss: 0.5967 - val_accuracy: 0.7846\n",
            "Epoch 158/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8680 - val_loss: 0.6106 - val_accuracy: 0.7793\n",
            "Epoch 159/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8670 - val_loss: 0.6047 - val_accuracy: 0.7768\n",
            "Epoch 160/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3168 - accuracy: 0.8678 - val_loss: 0.5919 - val_accuracy: 0.7908\n",
            "Epoch 161/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3124 - accuracy: 0.8691 - val_loss: 0.6049 - val_accuracy: 0.7882\n",
            "Epoch 162/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3149 - accuracy: 0.8687 - val_loss: 0.5993 - val_accuracy: 0.7823\n",
            "Epoch 163/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3146 - accuracy: 0.8696 - val_loss: 0.6028 - val_accuracy: 0.7874\n",
            "Epoch 164/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3129 - accuracy: 0.8700 - val_loss: 0.5965 - val_accuracy: 0.7842\n",
            "Epoch 165/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8689 - val_loss: 0.6027 - val_accuracy: 0.7946\n",
            "Epoch 166/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8696 - val_loss: 0.6049 - val_accuracy: 0.7958\n",
            "Epoch 167/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3156 - accuracy: 0.8677 - val_loss: 0.6125 - val_accuracy: 0.7834\n",
            "Epoch 168/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8702 - val_loss: 0.6116 - val_accuracy: 0.7914\n",
            "Epoch 169/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3123 - accuracy: 0.8688 - val_loss: 0.6033 - val_accuracy: 0.7874\n",
            "Epoch 170/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3147 - accuracy: 0.8695 - val_loss: 0.6058 - val_accuracy: 0.7880\n",
            "Epoch 171/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3122 - accuracy: 0.8718 - val_loss: 0.6025 - val_accuracy: 0.7956\n",
            "Epoch 172/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3096 - accuracy: 0.8706 - val_loss: 0.6018 - val_accuracy: 0.7886\n",
            "Epoch 173/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3108 - accuracy: 0.8699 - val_loss: 0.6121 - val_accuracy: 0.7874\n",
            "Epoch 174/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3115 - accuracy: 0.8703 - val_loss: 0.6142 - val_accuracy: 0.7844\n",
            "Epoch 175/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3104 - accuracy: 0.8715 - val_loss: 0.6075 - val_accuracy: 0.7933\n",
            "Epoch 176/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8700 - val_loss: 0.6174 - val_accuracy: 0.7950\n",
            "Epoch 177/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3110 - accuracy: 0.8720 - val_loss: 0.6113 - val_accuracy: 0.7903\n",
            "Epoch 178/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8701 - val_loss: 0.6386 - val_accuracy: 0.7612\n",
            "Epoch 179/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3085 - accuracy: 0.8709 - val_loss: 0.6139 - val_accuracy: 0.7876\n",
            "Epoch 180/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8689 - val_loss: 0.6411 - val_accuracy: 0.7823\n",
            "Epoch 181/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3117 - accuracy: 0.8691 - val_loss: 0.6297 - val_accuracy: 0.7851\n",
            "Epoch 182/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3093 - accuracy: 0.8705 - val_loss: 0.6172 - val_accuracy: 0.7863\n",
            "Epoch 183/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3109 - accuracy: 0.8698 - val_loss: 0.6222 - val_accuracy: 0.7893\n",
            "Epoch 184/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3078 - accuracy: 0.8726 - val_loss: 0.6274 - val_accuracy: 0.7918\n",
            "Epoch 185/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3068 - accuracy: 0.8716 - val_loss: 0.6515 - val_accuracy: 0.7578\n",
            "Epoch 186/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8715 - val_loss: 0.6197 - val_accuracy: 0.7836\n",
            "Epoch 187/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3077 - accuracy: 0.8713 - val_loss: 0.6264 - val_accuracy: 0.7865\n",
            "Epoch 188/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3094 - accuracy: 0.8702 - val_loss: 0.6321 - val_accuracy: 0.7922\n",
            "Epoch 189/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3066 - accuracy: 0.8736 - val_loss: 0.6300 - val_accuracy: 0.7914\n",
            "Epoch 190/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3079 - accuracy: 0.8704 - val_loss: 0.6340 - val_accuracy: 0.7745\n",
            "Epoch 191/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3080 - accuracy: 0.8707 - val_loss: 0.6254 - val_accuracy: 0.7908\n",
            "Epoch 192/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8729 - val_loss: 0.6189 - val_accuracy: 0.7840\n",
            "Epoch 193/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3061 - accuracy: 0.8723 - val_loss: 0.6376 - val_accuracy: 0.7916\n",
            "Epoch 194/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3098 - accuracy: 0.8711 - val_loss: 0.6337 - val_accuracy: 0.7891\n",
            "Epoch 195/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3061 - accuracy: 0.8728 - val_loss: 0.6322 - val_accuracy: 0.7745\n",
            "Epoch 196/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3071 - accuracy: 0.8717 - val_loss: 0.6221 - val_accuracy: 0.7774\n",
            "Epoch 197/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3053 - accuracy: 0.8726 - val_loss: 0.6272 - val_accuracy: 0.7855\n",
            "Epoch 198/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3059 - accuracy: 0.8737 - val_loss: 0.6316 - val_accuracy: 0.7914\n",
            "Epoch 199/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3084 - accuracy: 0.8723 - val_loss: 0.6413 - val_accuracy: 0.7825\n",
            "Epoch 200/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3050 - accuracy: 0.8720 - val_loss: 0.6464 - val_accuracy: 0.7886\n",
            "Epoch 201/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3071 - accuracy: 0.8696 - val_loss: 0.6378 - val_accuracy: 0.7903\n",
            "Epoch 202/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3046 - accuracy: 0.8724 - val_loss: 0.6380 - val_accuracy: 0.7838\n",
            "Epoch 203/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3028 - accuracy: 0.8724 - val_loss: 0.6369 - val_accuracy: 0.7823\n",
            "Epoch 204/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8706 - val_loss: 0.6361 - val_accuracy: 0.7927\n",
            "Epoch 205/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3055 - accuracy: 0.8718 - val_loss: 0.6423 - val_accuracy: 0.7939\n",
            "Epoch 206/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8709 - val_loss: 0.6424 - val_accuracy: 0.7768\n",
            "Epoch 207/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3048 - accuracy: 0.8742 - val_loss: 0.6539 - val_accuracy: 0.7791\n",
            "Epoch 208/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3049 - accuracy: 0.8742 - val_loss: 0.6445 - val_accuracy: 0.7916\n",
            "Epoch 209/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3045 - accuracy: 0.8724 - val_loss: 0.6464 - val_accuracy: 0.7764\n",
            "Epoch 210/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8733 - val_loss: 0.6370 - val_accuracy: 0.7872\n",
            "Epoch 211/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3036 - accuracy: 0.8732 - val_loss: 0.6525 - val_accuracy: 0.7810\n",
            "Epoch 212/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3042 - accuracy: 0.8734 - val_loss: 0.6499 - val_accuracy: 0.7810\n",
            "Epoch 213/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3045 - accuracy: 0.8694 - val_loss: 0.6505 - val_accuracy: 0.7777\n",
            "Epoch 214/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3033 - accuracy: 0.8751 - val_loss: 0.6371 - val_accuracy: 0.7895\n",
            "Epoch 215/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.6504 - val_accuracy: 0.7768\n",
            "Epoch 216/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3029 - accuracy: 0.8742 - val_loss: 0.6519 - val_accuracy: 0.7684\n",
            "Epoch 217/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.8716 - val_loss: 0.6440 - val_accuracy: 0.7829\n",
            "Epoch 218/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3021 - accuracy: 0.8715 - val_loss: 0.6436 - val_accuracy: 0.7840\n",
            "Epoch 219/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8726 - val_loss: 0.6551 - val_accuracy: 0.7717\n",
            "Epoch 220/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8725 - val_loss: 0.6502 - val_accuracy: 0.7882\n",
            "Epoch 221/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.8746 - val_loss: 0.6668 - val_accuracy: 0.7863\n",
            "Epoch 222/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8728 - val_loss: 0.6469 - val_accuracy: 0.7901\n",
            "Epoch 223/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3037 - accuracy: 0.8728 - val_loss: 0.6435 - val_accuracy: 0.7893\n",
            "Epoch 224/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3001 - accuracy: 0.8760 - val_loss: 0.6557 - val_accuracy: 0.7679\n",
            "Epoch 225/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.3023 - accuracy: 0.8720 - val_loss: 0.6543 - val_accuracy: 0.7793\n",
            "Epoch 226/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3002 - accuracy: 0.8723 - val_loss: 0.6655 - val_accuracy: 0.7665\n",
            "Epoch 227/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3014 - accuracy: 0.8732 - val_loss: 0.6451 - val_accuracy: 0.7859\n",
            "Epoch 228/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3032 - accuracy: 0.8740 - val_loss: 0.6497 - val_accuracy: 0.7865\n",
            "Epoch 229/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8749 - val_loss: 0.6559 - val_accuracy: 0.7912\n",
            "Epoch 230/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3003 - accuracy: 0.8748 - val_loss: 0.6677 - val_accuracy: 0.7825\n",
            "Epoch 231/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3017 - accuracy: 0.8742 - val_loss: 0.6618 - val_accuracy: 0.7821\n",
            "Epoch 232/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3016 - accuracy: 0.8719 - val_loss: 0.6629 - val_accuracy: 0.7808\n",
            "Epoch 233/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2985 - accuracy: 0.8749 - val_loss: 0.6629 - val_accuracy: 0.7770\n",
            "Epoch 234/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2997 - accuracy: 0.8751 - val_loss: 0.6750 - val_accuracy: 0.7895\n",
            "Epoch 235/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2990 - accuracy: 0.8726 - val_loss: 0.6582 - val_accuracy: 0.7870\n",
            "Epoch 236/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2984 - accuracy: 0.8748 - val_loss: 0.6581 - val_accuracy: 0.7810\n",
            "Epoch 237/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3020 - accuracy: 0.8755 - val_loss: 0.6648 - val_accuracy: 0.7751\n",
            "Epoch 238/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.3019 - accuracy: 0.8732 - val_loss: 0.6562 - val_accuracy: 0.7768\n",
            "Epoch 239/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2990 - accuracy: 0.8736 - val_loss: 0.6682 - val_accuracy: 0.7755\n",
            "Epoch 240/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8733 - val_loss: 0.6661 - val_accuracy: 0.7851\n",
            "Epoch 241/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8772 - val_loss: 0.6614 - val_accuracy: 0.7745\n",
            "Epoch 242/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2976 - accuracy: 0.8759 - val_loss: 0.6629 - val_accuracy: 0.7806\n",
            "Epoch 243/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2980 - accuracy: 0.8737 - val_loss: 0.6633 - val_accuracy: 0.7766\n",
            "Epoch 244/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2981 - accuracy: 0.8746 - val_loss: 0.6739 - val_accuracy: 0.7711\n",
            "Epoch 245/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2975 - accuracy: 0.8748 - val_loss: 0.6798 - val_accuracy: 0.7698\n",
            "Epoch 246/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2992 - accuracy: 0.8753 - val_loss: 0.6685 - val_accuracy: 0.7825\n",
            "Epoch 247/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2981 - accuracy: 0.8766 - val_loss: 0.6680 - val_accuracy: 0.7787\n",
            "Epoch 248/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2969 - accuracy: 0.8744 - val_loss: 0.6629 - val_accuracy: 0.7861\n",
            "Epoch 249/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2982 - accuracy: 0.8749 - val_loss: 0.6675 - val_accuracy: 0.7836\n",
            "Epoch 250/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2954 - accuracy: 0.8751 - val_loss: 0.6753 - val_accuracy: 0.7755\n",
            "Epoch 251/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2978 - accuracy: 0.8743 - val_loss: 0.6656 - val_accuracy: 0.7749\n",
            "Epoch 252/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8735 - val_loss: 0.6725 - val_accuracy: 0.7772\n",
            "Epoch 253/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2974 - accuracy: 0.8764 - val_loss: 0.6755 - val_accuracy: 0.7789\n",
            "Epoch 254/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2974 - accuracy: 0.8768 - val_loss: 0.6770 - val_accuracy: 0.7823\n",
            "Epoch 255/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2981 - accuracy: 0.8760 - val_loss: 0.6630 - val_accuracy: 0.7815\n",
            "Epoch 256/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8764 - val_loss: 0.6667 - val_accuracy: 0.7728\n",
            "Epoch 257/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2967 - accuracy: 0.8764 - val_loss: 0.6693 - val_accuracy: 0.7876\n",
            "Epoch 258/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8765 - val_loss: 0.6901 - val_accuracy: 0.7785\n",
            "Epoch 259/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2966 - accuracy: 0.8751 - val_loss: 0.6773 - val_accuracy: 0.7734\n",
            "Epoch 260/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8759 - val_loss: 0.6690 - val_accuracy: 0.7842\n",
            "Epoch 261/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2971 - accuracy: 0.8756 - val_loss: 0.6746 - val_accuracy: 0.7802\n",
            "Epoch 262/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2961 - accuracy: 0.8761 - val_loss: 0.7006 - val_accuracy: 0.7612\n",
            "Epoch 263/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.8753 - val_loss: 0.6769 - val_accuracy: 0.7739\n",
            "Epoch 264/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2964 - accuracy: 0.8753 - val_loss: 0.6763 - val_accuracy: 0.7836\n",
            "Epoch 265/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2956 - accuracy: 0.8768 - val_loss: 0.6706 - val_accuracy: 0.7836\n",
            "Epoch 266/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2955 - accuracy: 0.8764 - val_loss: 0.6804 - val_accuracy: 0.7747\n",
            "Epoch 267/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2953 - accuracy: 0.8756 - val_loss: 0.6918 - val_accuracy: 0.7840\n",
            "Epoch 268/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2956 - accuracy: 0.8763 - val_loss: 0.6835 - val_accuracy: 0.7734\n",
            "Epoch 269/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8764 - val_loss: 0.6878 - val_accuracy: 0.7781\n",
            "Epoch 270/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2947 - accuracy: 0.8771 - val_loss: 0.6830 - val_accuracy: 0.7724\n",
            "Epoch 271/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2937 - accuracy: 0.8773 - val_loss: 0.6867 - val_accuracy: 0.7595\n",
            "Epoch 272/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2968 - accuracy: 0.8774 - val_loss: 0.6852 - val_accuracy: 0.7800\n",
            "Epoch 273/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2940 - accuracy: 0.8758 - val_loss: 0.6842 - val_accuracy: 0.7711\n",
            "Epoch 274/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2945 - accuracy: 0.8757 - val_loss: 0.6827 - val_accuracy: 0.7810\n",
            "Epoch 275/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2933 - accuracy: 0.8785 - val_loss: 0.6905 - val_accuracy: 0.7658\n",
            "Epoch 276/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8763 - val_loss: 0.6834 - val_accuracy: 0.7840\n",
            "Epoch 277/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2949 - accuracy: 0.8773 - val_loss: 0.6859 - val_accuracy: 0.7819\n",
            "Epoch 278/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2922 - accuracy: 0.8760 - val_loss: 0.6854 - val_accuracy: 0.7848\n",
            "Epoch 279/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2933 - accuracy: 0.8780 - val_loss: 0.6869 - val_accuracy: 0.7747\n",
            "Epoch 280/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2931 - accuracy: 0.8764 - val_loss: 0.6953 - val_accuracy: 0.7654\n",
            "Epoch 281/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8760 - val_loss: 0.6931 - val_accuracy: 0.7755\n",
            "Epoch 282/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2912 - accuracy: 0.8780 - val_loss: 0.6839 - val_accuracy: 0.7819\n",
            "Epoch 283/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2926 - accuracy: 0.8786 - val_loss: 0.6931 - val_accuracy: 0.7650\n",
            "Epoch 284/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2910 - accuracy: 0.8781 - val_loss: 0.7083 - val_accuracy: 0.7717\n",
            "Epoch 285/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2921 - accuracy: 0.8782 - val_loss: 0.6928 - val_accuracy: 0.7751\n",
            "Epoch 286/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2944 - accuracy: 0.8790 - val_loss: 0.6953 - val_accuracy: 0.7825\n",
            "Epoch 287/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2918 - accuracy: 0.8779 - val_loss: 0.6951 - val_accuracy: 0.7724\n",
            "Epoch 288/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2924 - accuracy: 0.8790 - val_loss: 0.6961 - val_accuracy: 0.7819\n",
            "Epoch 289/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2921 - accuracy: 0.8778 - val_loss: 0.6874 - val_accuracy: 0.7808\n",
            "Epoch 290/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2915 - accuracy: 0.8771 - val_loss: 0.6882 - val_accuracy: 0.7815\n",
            "Epoch 291/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2915 - accuracy: 0.8781 - val_loss: 0.7032 - val_accuracy: 0.7722\n",
            "Epoch 292/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2917 - accuracy: 0.8785 - val_loss: 0.6992 - val_accuracy: 0.7726\n",
            "Epoch 293/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2908 - accuracy: 0.8781 - val_loss: 0.6891 - val_accuracy: 0.7726\n",
            "Epoch 294/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2927 - accuracy: 0.8758 - val_loss: 0.7078 - val_accuracy: 0.7772\n",
            "Epoch 295/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2914 - accuracy: 0.8791 - val_loss: 0.6949 - val_accuracy: 0.7785\n",
            "Epoch 296/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2911 - accuracy: 0.8785 - val_loss: 0.6962 - val_accuracy: 0.7825\n",
            "Epoch 297/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.8763 - val_loss: 0.6855 - val_accuracy: 0.7836\n",
            "Epoch 298/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8755 - val_loss: 0.7148 - val_accuracy: 0.7709\n",
            "Epoch 299/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2913 - accuracy: 0.8786 - val_loss: 0.6998 - val_accuracy: 0.7838\n",
            "Epoch 300/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2896 - accuracy: 0.8791 - val_loss: 0.7079 - val_accuracy: 0.7669\n",
            "Epoch 301/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8784 - val_loss: 0.6918 - val_accuracy: 0.7832\n",
            "Epoch 302/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2877 - accuracy: 0.8786 - val_loss: 0.7095 - val_accuracy: 0.7660\n",
            "Epoch 303/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2939 - accuracy: 0.8787 - val_loss: 0.6919 - val_accuracy: 0.7789\n",
            "Epoch 304/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2902 - accuracy: 0.8801 - val_loss: 0.6993 - val_accuracy: 0.7758\n",
            "Epoch 305/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2919 - accuracy: 0.8796 - val_loss: 0.7071 - val_accuracy: 0.7715\n",
            "Epoch 306/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2911 - accuracy: 0.8783 - val_loss: 0.6990 - val_accuracy: 0.7798\n",
            "Epoch 307/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2881 - accuracy: 0.8817 - val_loss: 0.7002 - val_accuracy: 0.7736\n",
            "Epoch 308/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8793 - val_loss: 0.7025 - val_accuracy: 0.7823\n",
            "Epoch 309/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2910 - accuracy: 0.8766 - val_loss: 0.7006 - val_accuracy: 0.7715\n",
            "Epoch 310/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8788 - val_loss: 0.7036 - val_accuracy: 0.7889\n",
            "Epoch 311/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2902 - accuracy: 0.8790 - val_loss: 0.7046 - val_accuracy: 0.7821\n",
            "Epoch 312/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2892 - accuracy: 0.8772 - val_loss: 0.6974 - val_accuracy: 0.7762\n",
            "Epoch 313/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.8744 - val_loss: 0.7087 - val_accuracy: 0.7785\n",
            "Epoch 314/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2883 - accuracy: 0.8794 - val_loss: 0.7198 - val_accuracy: 0.7591\n",
            "Epoch 315/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2894 - accuracy: 0.8784 - val_loss: 0.7102 - val_accuracy: 0.7745\n",
            "Epoch 316/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2901 - accuracy: 0.8770 - val_loss: 0.7115 - val_accuracy: 0.7705\n",
            "Epoch 317/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8791 - val_loss: 0.7027 - val_accuracy: 0.7734\n",
            "Epoch 318/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2882 - accuracy: 0.8797 - val_loss: 0.7064 - val_accuracy: 0.7878\n",
            "Epoch 319/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.8810 - val_loss: 0.7027 - val_accuracy: 0.7724\n",
            "Epoch 320/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2876 - accuracy: 0.8799 - val_loss: 0.7150 - val_accuracy: 0.7832\n",
            "Epoch 321/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2888 - accuracy: 0.8792 - val_loss: 0.7092 - val_accuracy: 0.7701\n",
            "Epoch 322/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8789 - val_loss: 0.7034 - val_accuracy: 0.7829\n",
            "Epoch 323/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.8773 - val_loss: 0.7120 - val_accuracy: 0.7834\n",
            "Epoch 324/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2885 - accuracy: 0.8802 - val_loss: 0.7199 - val_accuracy: 0.7665\n",
            "Epoch 325/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2870 - accuracy: 0.8803 - val_loss: 0.7245 - val_accuracy: 0.7931\n",
            "Epoch 326/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2868 - accuracy: 0.8801 - val_loss: 0.7117 - val_accuracy: 0.7760\n",
            "Epoch 327/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2860 - accuracy: 0.8811 - val_loss: 0.7116 - val_accuracy: 0.7787\n",
            "Epoch 328/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2871 - accuracy: 0.8784 - val_loss: 0.7109 - val_accuracy: 0.7793\n",
            "Epoch 329/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2879 - accuracy: 0.8795 - val_loss: 0.7195 - val_accuracy: 0.7821\n",
            "Epoch 330/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2867 - accuracy: 0.8811 - val_loss: 0.7225 - val_accuracy: 0.7762\n",
            "Epoch 331/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2872 - accuracy: 0.8798 - val_loss: 0.7029 - val_accuracy: 0.7802\n",
            "Epoch 332/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.8777 - val_loss: 0.7261 - val_accuracy: 0.7804\n",
            "Epoch 333/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.8800 - val_loss: 0.7059 - val_accuracy: 0.7857\n",
            "Epoch 334/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2855 - accuracy: 0.8792 - val_loss: 0.7145 - val_accuracy: 0.7876\n",
            "Epoch 335/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2852 - accuracy: 0.8833 - val_loss: 0.7240 - val_accuracy: 0.7656\n",
            "Epoch 336/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2862 - accuracy: 0.8812 - val_loss: 0.7137 - val_accuracy: 0.7893\n",
            "Epoch 337/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8811 - val_loss: 0.7177 - val_accuracy: 0.7802\n",
            "Epoch 338/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2866 - accuracy: 0.8810 - val_loss: 0.7066 - val_accuracy: 0.7696\n",
            "Epoch 339/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8822 - val_loss: 0.7189 - val_accuracy: 0.7908\n",
            "Epoch 340/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8804 - val_loss: 0.7124 - val_accuracy: 0.7732\n",
            "Epoch 341/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2894 - accuracy: 0.8803 - val_loss: 0.7255 - val_accuracy: 0.7728\n",
            "Epoch 342/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2889 - accuracy: 0.8785 - val_loss: 0.7132 - val_accuracy: 0.7842\n",
            "Epoch 343/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8791 - val_loss: 0.7200 - val_accuracy: 0.7690\n",
            "Epoch 344/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2846 - accuracy: 0.8802 - val_loss: 0.7146 - val_accuracy: 0.7741\n",
            "Epoch 345/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2849 - accuracy: 0.8804 - val_loss: 0.7245 - val_accuracy: 0.7760\n",
            "Epoch 346/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2843 - accuracy: 0.8802 - val_loss: 0.7225 - val_accuracy: 0.7772\n",
            "Epoch 347/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2844 - accuracy: 0.8811 - val_loss: 0.7312 - val_accuracy: 0.7671\n",
            "Epoch 348/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8790 - val_loss: 0.7155 - val_accuracy: 0.7760\n",
            "Epoch 349/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2848 - accuracy: 0.8811 - val_loss: 0.7216 - val_accuracy: 0.7722\n",
            "Epoch 350/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2854 - accuracy: 0.8813 - val_loss: 0.7217 - val_accuracy: 0.7838\n",
            "Epoch 351/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2842 - accuracy: 0.8803 - val_loss: 0.7228 - val_accuracy: 0.7846\n",
            "Epoch 352/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2838 - accuracy: 0.8812 - val_loss: 0.7267 - val_accuracy: 0.7660\n",
            "Epoch 353/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.8815 - val_loss: 0.7387 - val_accuracy: 0.7713\n",
            "Epoch 354/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8810 - val_loss: 0.7354 - val_accuracy: 0.7644\n",
            "Epoch 355/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2858 - accuracy: 0.8796 - val_loss: 0.7290 - val_accuracy: 0.7682\n",
            "Epoch 356/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2844 - accuracy: 0.8795 - val_loss: 0.7190 - val_accuracy: 0.7787\n",
            "Epoch 357/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.8784 - val_loss: 0.7268 - val_accuracy: 0.7874\n",
            "Epoch 358/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2849 - accuracy: 0.8808 - val_loss: 0.7292 - val_accuracy: 0.7726\n",
            "Epoch 359/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.8832 - val_loss: 0.7264 - val_accuracy: 0.7897\n",
            "Epoch 360/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2855 - accuracy: 0.8806 - val_loss: 0.7326 - val_accuracy: 0.7584\n",
            "Epoch 361/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2856 - accuracy: 0.8798 - val_loss: 0.7254 - val_accuracy: 0.7675\n",
            "Epoch 362/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.8831 - val_loss: 0.7163 - val_accuracy: 0.7701\n",
            "Epoch 363/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2815 - accuracy: 0.8823 - val_loss: 0.7196 - val_accuracy: 0.7810\n",
            "Epoch 364/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.8823 - val_loss: 0.7249 - val_accuracy: 0.7796\n",
            "Epoch 365/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2853 - accuracy: 0.8816 - val_loss: 0.7333 - val_accuracy: 0.7899\n",
            "Epoch 366/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2819 - accuracy: 0.8812 - val_loss: 0.7271 - val_accuracy: 0.7810\n",
            "Epoch 367/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2866 - accuracy: 0.8812 - val_loss: 0.7224 - val_accuracy: 0.7798\n",
            "Epoch 368/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.8821 - val_loss: 0.7321 - val_accuracy: 0.7682\n",
            "Epoch 369/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.8830 - val_loss: 0.7412 - val_accuracy: 0.7519\n",
            "Epoch 370/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8842 - val_loss: 0.7313 - val_accuracy: 0.7842\n",
            "Epoch 371/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8843 - val_loss: 0.7394 - val_accuracy: 0.7701\n",
            "Epoch 372/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.8820 - val_loss: 0.7452 - val_accuracy: 0.7840\n",
            "Epoch 373/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2835 - accuracy: 0.8827 - val_loss: 0.7293 - val_accuracy: 0.7787\n",
            "Epoch 374/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.8821 - val_loss: 0.7331 - val_accuracy: 0.7728\n",
            "Epoch 375/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2799 - accuracy: 0.8817 - val_loss: 0.7367 - val_accuracy: 0.7722\n",
            "Epoch 376/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2830 - accuracy: 0.8802 - val_loss: 0.7389 - val_accuracy: 0.7709\n",
            "Epoch 377/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2796 - accuracy: 0.8831 - val_loss: 0.7322 - val_accuracy: 0.7796\n",
            "Epoch 378/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2816 - accuracy: 0.8820 - val_loss: 0.7334 - val_accuracy: 0.7783\n",
            "Epoch 379/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2831 - accuracy: 0.8823 - val_loss: 0.7299 - val_accuracy: 0.7815\n",
            "Epoch 380/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2829 - accuracy: 0.8803 - val_loss: 0.7421 - val_accuracy: 0.7821\n",
            "Epoch 381/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2813 - accuracy: 0.8839 - val_loss: 0.7386 - val_accuracy: 0.7747\n",
            "Epoch 382/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.8812 - val_loss: 0.7353 - val_accuracy: 0.7823\n",
            "Epoch 383/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.8814 - val_loss: 0.7293 - val_accuracy: 0.7707\n",
            "Epoch 384/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8812 - val_loss: 0.7500 - val_accuracy: 0.7580\n",
            "Epoch 385/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2812 - accuracy: 0.8816 - val_loss: 0.7607 - val_accuracy: 0.7565\n",
            "Epoch 386/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2807 - accuracy: 0.8809 - val_loss: 0.7392 - val_accuracy: 0.7810\n",
            "Epoch 387/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2825 - accuracy: 0.8822 - val_loss: 0.7283 - val_accuracy: 0.7753\n",
            "Epoch 388/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8823 - val_loss: 0.7354 - val_accuracy: 0.7895\n",
            "Epoch 389/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2815 - accuracy: 0.8825 - val_loss: 0.7469 - val_accuracy: 0.7876\n",
            "Epoch 390/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2814 - accuracy: 0.8814 - val_loss: 0.7329 - val_accuracy: 0.7770\n",
            "Epoch 391/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8833 - val_loss: 0.7376 - val_accuracy: 0.7823\n",
            "Epoch 392/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2812 - accuracy: 0.8816 - val_loss: 0.7341 - val_accuracy: 0.7798\n",
            "Epoch 393/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8818 - val_loss: 0.7572 - val_accuracy: 0.7595\n",
            "Epoch 394/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.8812 - val_loss: 0.7407 - val_accuracy: 0.7886\n",
            "Epoch 395/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2794 - accuracy: 0.8807 - val_loss: 0.7470 - val_accuracy: 0.7508\n",
            "Epoch 396/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2787 - accuracy: 0.8828 - val_loss: 0.7357 - val_accuracy: 0.7772\n",
            "Epoch 397/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2779 - accuracy: 0.8847 - val_loss: 0.7421 - val_accuracy: 0.7768\n",
            "Epoch 398/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8831 - val_loss: 0.7523 - val_accuracy: 0.7810\n",
            "Epoch 399/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2796 - accuracy: 0.8830 - val_loss: 0.7499 - val_accuracy: 0.7713\n",
            "Epoch 400/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2805 - accuracy: 0.8824 - val_loss: 0.7505 - val_accuracy: 0.7889\n",
            "Epoch 401/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2819 - accuracy: 0.8815 - val_loss: 0.7472 - val_accuracy: 0.7743\n",
            "Epoch 402/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.8832 - val_loss: 0.7569 - val_accuracy: 0.7758\n",
            "Epoch 403/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.8829 - val_loss: 0.7546 - val_accuracy: 0.7538\n",
            "Epoch 404/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2802 - accuracy: 0.8831 - val_loss: 0.7513 - val_accuracy: 0.7743\n",
            "Epoch 405/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2780 - accuracy: 0.8842 - val_loss: 0.7486 - val_accuracy: 0.7798\n",
            "Epoch 406/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2774 - accuracy: 0.8841 - val_loss: 0.7529 - val_accuracy: 0.7762\n",
            "Epoch 407/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2789 - accuracy: 0.8822 - val_loss: 0.7591 - val_accuracy: 0.7724\n",
            "Epoch 408/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2797 - accuracy: 0.8831 - val_loss: 0.7403 - val_accuracy: 0.7846\n",
            "Epoch 409/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2815 - accuracy: 0.8822 - val_loss: 0.7559 - val_accuracy: 0.7749\n",
            "Epoch 410/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2820 - accuracy: 0.8833 - val_loss: 0.7435 - val_accuracy: 0.7783\n",
            "Epoch 411/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.8844 - val_loss: 0.7675 - val_accuracy: 0.7593\n",
            "Epoch 412/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2784 - accuracy: 0.8835 - val_loss: 0.7474 - val_accuracy: 0.7717\n",
            "Epoch 413/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8826 - val_loss: 0.7469 - val_accuracy: 0.7774\n",
            "Epoch 414/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2785 - accuracy: 0.8845 - val_loss: 0.7491 - val_accuracy: 0.7713\n",
            "Epoch 415/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2783 - accuracy: 0.8843 - val_loss: 0.7460 - val_accuracy: 0.7791\n",
            "Epoch 416/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2776 - accuracy: 0.8843 - val_loss: 0.7517 - val_accuracy: 0.7673\n",
            "Epoch 417/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2779 - accuracy: 0.8840 - val_loss: 0.7573 - val_accuracy: 0.7838\n",
            "Epoch 418/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2790 - accuracy: 0.8852 - val_loss: 0.7497 - val_accuracy: 0.7694\n",
            "Epoch 419/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2788 - accuracy: 0.8827 - val_loss: 0.7526 - val_accuracy: 0.7836\n",
            "Epoch 420/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.8840 - val_loss: 0.7520 - val_accuracy: 0.7688\n",
            "Epoch 421/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2759 - accuracy: 0.8846 - val_loss: 0.7540 - val_accuracy: 0.7688\n",
            "Epoch 422/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2787 - accuracy: 0.8827 - val_loss: 0.7547 - val_accuracy: 0.7646\n",
            "Epoch 423/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.8831 - val_loss: 0.7603 - val_accuracy: 0.7840\n",
            "Epoch 424/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2783 - accuracy: 0.8838 - val_loss: 0.7540 - val_accuracy: 0.7743\n",
            "Epoch 425/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2798 - accuracy: 0.8839 - val_loss: 0.7675 - val_accuracy: 0.7557\n",
            "Epoch 426/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2766 - accuracy: 0.8829 - val_loss: 0.7637 - val_accuracy: 0.7641\n",
            "Epoch 427/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.8822 - val_loss: 0.7512 - val_accuracy: 0.7648\n",
            "Epoch 428/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.8835 - val_loss: 0.7652 - val_accuracy: 0.7694\n",
            "Epoch 429/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8843 - val_loss: 0.7519 - val_accuracy: 0.7798\n",
            "Epoch 430/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.8841 - val_loss: 0.7509 - val_accuracy: 0.7686\n",
            "Epoch 431/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2811 - accuracy: 0.8837 - val_loss: 0.7587 - val_accuracy: 0.7688\n",
            "Epoch 432/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8846 - val_loss: 0.7626 - val_accuracy: 0.7783\n",
            "Epoch 433/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.8846 - val_loss: 0.7579 - val_accuracy: 0.7783\n",
            "Epoch 434/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2774 - accuracy: 0.8849 - val_loss: 0.7609 - val_accuracy: 0.7641\n",
            "Epoch 435/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2765 - accuracy: 0.8840 - val_loss: 0.7653 - val_accuracy: 0.7688\n",
            "Epoch 436/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2786 - accuracy: 0.8834 - val_loss: 0.7662 - val_accuracy: 0.7760\n",
            "Epoch 437/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2766 - accuracy: 0.8851 - val_loss: 0.7580 - val_accuracy: 0.7806\n",
            "Epoch 438/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.8844 - val_loss: 0.7577 - val_accuracy: 0.7608\n",
            "Epoch 439/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2783 - accuracy: 0.8848 - val_loss: 0.7696 - val_accuracy: 0.7561\n",
            "Epoch 440/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8856 - val_loss: 0.7519 - val_accuracy: 0.7827\n",
            "Epoch 441/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2788 - accuracy: 0.8833 - val_loss: 0.7577 - val_accuracy: 0.7739\n",
            "Epoch 442/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2762 - accuracy: 0.8823 - val_loss: 0.7566 - val_accuracy: 0.7829\n",
            "Epoch 443/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2781 - accuracy: 0.8841 - val_loss: 0.7638 - val_accuracy: 0.7578\n",
            "Epoch 444/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2740 - accuracy: 0.8863 - val_loss: 0.7544 - val_accuracy: 0.7810\n",
            "Epoch 445/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2758 - accuracy: 0.8843 - val_loss: 0.7551 - val_accuracy: 0.7720\n",
            "Epoch 446/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2758 - accuracy: 0.8840 - val_loss: 0.7658 - val_accuracy: 0.7698\n",
            "Epoch 447/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8847 - val_loss: 0.7750 - val_accuracy: 0.7853\n",
            "Epoch 448/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8827 - val_loss: 0.7560 - val_accuracy: 0.7726\n",
            "Epoch 449/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.8857 - val_loss: 0.7693 - val_accuracy: 0.7836\n",
            "Epoch 450/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2786 - accuracy: 0.8837 - val_loss: 0.7711 - val_accuracy: 0.7582\n",
            "Epoch 451/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8859 - val_loss: 0.7740 - val_accuracy: 0.7694\n",
            "Epoch 452/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8862 - val_loss: 0.7659 - val_accuracy: 0.7698\n",
            "Epoch 453/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2763 - accuracy: 0.8830 - val_loss: 0.7597 - val_accuracy: 0.7677\n",
            "Epoch 454/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2759 - accuracy: 0.8839 - val_loss: 0.7717 - val_accuracy: 0.7791\n",
            "Epoch 455/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2766 - accuracy: 0.8843 - val_loss: 0.7526 - val_accuracy: 0.7747\n",
            "Epoch 456/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2748 - accuracy: 0.8853 - val_loss: 0.7643 - val_accuracy: 0.7582\n",
            "Epoch 457/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2742 - accuracy: 0.8844 - val_loss: 0.7623 - val_accuracy: 0.7815\n",
            "Epoch 458/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2754 - accuracy: 0.8829 - val_loss: 0.7659 - val_accuracy: 0.7758\n",
            "Epoch 459/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2737 - accuracy: 0.8865 - val_loss: 0.7603 - val_accuracy: 0.7715\n",
            "Epoch 460/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2777 - accuracy: 0.8851 - val_loss: 0.7537 - val_accuracy: 0.7753\n",
            "Epoch 461/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2734 - accuracy: 0.8853 - val_loss: 0.7825 - val_accuracy: 0.7587\n",
            "Epoch 462/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2749 - accuracy: 0.8850 - val_loss: 0.7686 - val_accuracy: 0.7688\n",
            "Epoch 463/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2750 - accuracy: 0.8834 - val_loss: 0.7629 - val_accuracy: 0.7720\n",
            "Epoch 464/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2760 - accuracy: 0.8833 - val_loss: 0.7746 - val_accuracy: 0.7745\n",
            "Epoch 465/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2754 - accuracy: 0.8853 - val_loss: 0.7562 - val_accuracy: 0.7565\n",
            "Epoch 466/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2730 - accuracy: 0.8852 - val_loss: 0.7643 - val_accuracy: 0.7745\n",
            "Epoch 467/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2723 - accuracy: 0.8860 - val_loss: 0.7519 - val_accuracy: 0.7673\n",
            "Epoch 468/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2753 - accuracy: 0.8840 - val_loss: 0.7602 - val_accuracy: 0.7817\n",
            "Epoch 469/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2729 - accuracy: 0.8853 - val_loss: 0.7609 - val_accuracy: 0.7783\n",
            "Epoch 470/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8866 - val_loss: 0.7625 - val_accuracy: 0.7734\n",
            "Epoch 471/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2760 - accuracy: 0.8845 - val_loss: 0.7565 - val_accuracy: 0.7741\n",
            "Epoch 472/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2739 - accuracy: 0.8863 - val_loss: 0.7619 - val_accuracy: 0.7641\n",
            "Epoch 473/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2731 - accuracy: 0.8867 - val_loss: 0.7649 - val_accuracy: 0.7654\n",
            "Epoch 474/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2711 - accuracy: 0.8861 - val_loss: 0.7632 - val_accuracy: 0.7561\n",
            "Epoch 475/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2730 - accuracy: 0.8860 - val_loss: 0.7728 - val_accuracy: 0.7694\n",
            "Epoch 476/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2733 - accuracy: 0.8863 - val_loss: 0.7662 - val_accuracy: 0.7677\n",
            "Epoch 477/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8867 - val_loss: 0.7682 - val_accuracy: 0.7684\n",
            "Epoch 478/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2744 - accuracy: 0.8834 - val_loss: 0.7922 - val_accuracy: 0.7703\n",
            "Epoch 479/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8852 - val_loss: 0.7664 - val_accuracy: 0.7698\n",
            "Epoch 480/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2745 - accuracy: 0.8844 - val_loss: 0.7725 - val_accuracy: 0.7646\n",
            "Epoch 481/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.8883 - val_loss: 0.7729 - val_accuracy: 0.7705\n",
            "Epoch 482/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8826 - val_loss: 0.7725 - val_accuracy: 0.7682\n",
            "Epoch 483/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8852 - val_loss: 0.7808 - val_accuracy: 0.7671\n",
            "Epoch 484/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2752 - accuracy: 0.8858 - val_loss: 0.7659 - val_accuracy: 0.7758\n",
            "Epoch 485/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2713 - accuracy: 0.8880 - val_loss: 0.7735 - val_accuracy: 0.7768\n",
            "Epoch 486/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2731 - accuracy: 0.8850 - val_loss: 0.7611 - val_accuracy: 0.7722\n",
            "Epoch 487/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2712 - accuracy: 0.8870 - val_loss: 0.7656 - val_accuracy: 0.7768\n",
            "Epoch 488/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2715 - accuracy: 0.8857 - val_loss: 0.7680 - val_accuracy: 0.7793\n",
            "Epoch 489/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2703 - accuracy: 0.8863 - val_loss: 0.7668 - val_accuracy: 0.7739\n",
            "Epoch 490/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.8864 - val_loss: 0.7709 - val_accuracy: 0.7694\n",
            "Epoch 491/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.8846 - val_loss: 0.7782 - val_accuracy: 0.7650\n",
            "Epoch 492/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8852 - val_loss: 0.7607 - val_accuracy: 0.7768\n",
            "Epoch 493/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.8849 - val_loss: 0.7586 - val_accuracy: 0.7812\n",
            "Epoch 494/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2721 - accuracy: 0.8868 - val_loss: 0.7811 - val_accuracy: 0.7722\n",
            "Epoch 495/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2735 - accuracy: 0.8862 - val_loss: 0.7623 - val_accuracy: 0.7696\n",
            "Epoch 496/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2729 - accuracy: 0.8852 - val_loss: 0.7694 - val_accuracy: 0.7768\n",
            "Epoch 497/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2714 - accuracy: 0.8878 - val_loss: 0.7708 - val_accuracy: 0.7751\n",
            "Epoch 498/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.8865 - val_loss: 0.7800 - val_accuracy: 0.7717\n",
            "Epoch 499/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2709 - accuracy: 0.8856 - val_loss: 0.7835 - val_accuracy: 0.7481\n",
            "Epoch 500/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2707 - accuracy: 0.8851 - val_loss: 0.7812 - val_accuracy: 0.7627\n",
            "Epoch 501/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8865 - val_loss: 0.7716 - val_accuracy: 0.7749\n",
            "Epoch 502/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2740 - accuracy: 0.8887 - val_loss: 0.7712 - val_accuracy: 0.7745\n",
            "Epoch 503/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.8870 - val_loss: 0.7732 - val_accuracy: 0.7863\n",
            "Epoch 504/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2721 - accuracy: 0.8860 - val_loss: 0.7624 - val_accuracy: 0.7690\n",
            "Epoch 505/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2719 - accuracy: 0.8865 - val_loss: 0.7784 - val_accuracy: 0.7625\n",
            "Epoch 506/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2732 - accuracy: 0.8867 - val_loss: 0.7772 - val_accuracy: 0.7823\n",
            "Epoch 507/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.8871 - val_loss: 0.7722 - val_accuracy: 0.7667\n",
            "Epoch 508/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.8881 - val_loss: 0.7917 - val_accuracy: 0.7616\n",
            "Epoch 509/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2735 - accuracy: 0.8850 - val_loss: 0.7808 - val_accuracy: 0.7711\n",
            "Epoch 510/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.8868 - val_loss: 0.7881 - val_accuracy: 0.7679\n",
            "Epoch 511/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2708 - accuracy: 0.8864 - val_loss: 0.7718 - val_accuracy: 0.7677\n",
            "Epoch 512/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2704 - accuracy: 0.8874 - val_loss: 0.7867 - val_accuracy: 0.7682\n",
            "Epoch 513/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2720 - accuracy: 0.8861 - val_loss: 0.7902 - val_accuracy: 0.7606\n",
            "Epoch 514/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2689 - accuracy: 0.8853 - val_loss: 0.7864 - val_accuracy: 0.7819\n",
            "Epoch 515/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2712 - accuracy: 0.8867 - val_loss: 0.7848 - val_accuracy: 0.7793\n",
            "Epoch 516/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2696 - accuracy: 0.8878 - val_loss: 0.7699 - val_accuracy: 0.7785\n",
            "Epoch 517/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.8851 - val_loss: 0.7889 - val_accuracy: 0.7722\n",
            "Epoch 518/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2696 - accuracy: 0.8852 - val_loss: 0.7706 - val_accuracy: 0.7751\n",
            "Epoch 519/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.8866 - val_loss: 0.7700 - val_accuracy: 0.7749\n",
            "Epoch 520/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8891 - val_loss: 0.7762 - val_accuracy: 0.7762\n",
            "Epoch 521/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2680 - accuracy: 0.8884 - val_loss: 0.7788 - val_accuracy: 0.7747\n",
            "Epoch 522/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.8862 - val_loss: 0.7763 - val_accuracy: 0.7758\n",
            "Epoch 523/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8853 - val_loss: 0.7784 - val_accuracy: 0.7745\n",
            "Epoch 524/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2697 - accuracy: 0.8872 - val_loss: 0.7780 - val_accuracy: 0.7715\n",
            "Epoch 525/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2722 - accuracy: 0.8857 - val_loss: 0.7848 - val_accuracy: 0.7576\n",
            "Epoch 526/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2690 - accuracy: 0.8874 - val_loss: 0.7825 - val_accuracy: 0.7553\n",
            "Epoch 527/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8872 - val_loss: 0.7756 - val_accuracy: 0.7639\n",
            "Epoch 528/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8863 - val_loss: 0.7879 - val_accuracy: 0.7620\n",
            "Epoch 529/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2687 - accuracy: 0.8868 - val_loss: 0.7925 - val_accuracy: 0.7834\n",
            "Epoch 530/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2680 - accuracy: 0.8871 - val_loss: 0.7790 - val_accuracy: 0.7639\n",
            "Epoch 531/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2690 - accuracy: 0.8880 - val_loss: 0.7819 - val_accuracy: 0.7635\n",
            "Epoch 532/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8878 - val_loss: 0.7793 - val_accuracy: 0.7777\n",
            "Epoch 533/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.8852 - val_loss: 0.7954 - val_accuracy: 0.7802\n",
            "Epoch 534/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2702 - accuracy: 0.8857 - val_loss: 0.7866 - val_accuracy: 0.7855\n",
            "Epoch 535/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2681 - accuracy: 0.8858 - val_loss: 0.7843 - val_accuracy: 0.7741\n",
            "Epoch 536/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2690 - accuracy: 0.8901 - val_loss: 0.7864 - val_accuracy: 0.7622\n",
            "Epoch 537/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2688 - accuracy: 0.8867 - val_loss: 0.7843 - val_accuracy: 0.7610\n",
            "Epoch 538/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8893 - val_loss: 0.7844 - val_accuracy: 0.7736\n",
            "Epoch 539/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.8882 - val_loss: 0.8025 - val_accuracy: 0.7521\n",
            "Epoch 540/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8869 - val_loss: 0.8004 - val_accuracy: 0.7603\n",
            "Epoch 541/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.8873 - val_loss: 0.7836 - val_accuracy: 0.7741\n",
            "Epoch 542/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.8876 - val_loss: 0.7919 - val_accuracy: 0.7692\n",
            "Epoch 543/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.8871 - val_loss: 0.7938 - val_accuracy: 0.7646\n",
            "Epoch 544/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2665 - accuracy: 0.8881 - val_loss: 0.7747 - val_accuracy: 0.7684\n",
            "Epoch 545/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2701 - accuracy: 0.8871 - val_loss: 0.7945 - val_accuracy: 0.7496\n",
            "Epoch 546/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2671 - accuracy: 0.8885 - val_loss: 0.7859 - val_accuracy: 0.7796\n",
            "Epoch 547/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2684 - accuracy: 0.8864 - val_loss: 0.8105 - val_accuracy: 0.7572\n",
            "Epoch 548/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.8875 - val_loss: 0.7943 - val_accuracy: 0.7639\n",
            "Epoch 549/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2663 - accuracy: 0.8898 - val_loss: 0.7936 - val_accuracy: 0.7665\n",
            "Epoch 550/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2672 - accuracy: 0.8879 - val_loss: 0.8001 - val_accuracy: 0.7667\n",
            "Epoch 551/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8851 - val_loss: 0.7883 - val_accuracy: 0.7872\n",
            "Epoch 552/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2690 - accuracy: 0.8849 - val_loss: 0.7815 - val_accuracy: 0.7815\n",
            "Epoch 553/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2692 - accuracy: 0.8876 - val_loss: 0.8036 - val_accuracy: 0.7671\n",
            "Epoch 554/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2668 - accuracy: 0.8868 - val_loss: 0.7931 - val_accuracy: 0.7502\n",
            "Epoch 555/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2681 - accuracy: 0.8892 - val_loss: 0.7952 - val_accuracy: 0.7625\n",
            "Epoch 556/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2668 - accuracy: 0.8879 - val_loss: 0.7922 - val_accuracy: 0.7743\n",
            "Epoch 557/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2695 - accuracy: 0.8869 - val_loss: 0.7879 - val_accuracy: 0.7669\n",
            "Epoch 558/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.8888 - val_loss: 0.7917 - val_accuracy: 0.7606\n",
            "Epoch 559/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8875 - val_loss: 0.7929 - val_accuracy: 0.7587\n",
            "Epoch 560/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8899 - val_loss: 0.8085 - val_accuracy: 0.7861\n",
            "Epoch 561/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2685 - accuracy: 0.8889 - val_loss: 0.8094 - val_accuracy: 0.7724\n",
            "Epoch 562/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8890 - val_loss: 0.7883 - val_accuracy: 0.7606\n",
            "Epoch 563/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2677 - accuracy: 0.8870 - val_loss: 0.7900 - val_accuracy: 0.7612\n",
            "Epoch 564/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2672 - accuracy: 0.8886 - val_loss: 0.7994 - val_accuracy: 0.7663\n",
            "Epoch 565/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2682 - accuracy: 0.8890 - val_loss: 0.8133 - val_accuracy: 0.7789\n",
            "Epoch 566/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2695 - accuracy: 0.8870 - val_loss: 0.7924 - val_accuracy: 0.7758\n",
            "Epoch 567/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.8887 - val_loss: 0.7944 - val_accuracy: 0.7639\n",
            "Epoch 568/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.8884 - val_loss: 0.7946 - val_accuracy: 0.7667\n",
            "Epoch 569/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2676 - accuracy: 0.8867 - val_loss: 0.8023 - val_accuracy: 0.7525\n",
            "Epoch 570/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2666 - accuracy: 0.8882 - val_loss: 0.7947 - val_accuracy: 0.7690\n",
            "Epoch 571/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2674 - accuracy: 0.8887 - val_loss: 0.7921 - val_accuracy: 0.7781\n",
            "Epoch 572/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2651 - accuracy: 0.8898 - val_loss: 0.8022 - val_accuracy: 0.7644\n",
            "Epoch 573/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8880 - val_loss: 0.7973 - val_accuracy: 0.7633\n",
            "Epoch 574/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2636 - accuracy: 0.8895 - val_loss: 0.8017 - val_accuracy: 0.7808\n",
            "Epoch 575/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2652 - accuracy: 0.8883 - val_loss: 0.7993 - val_accuracy: 0.7677\n",
            "Epoch 576/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2667 - accuracy: 0.8886 - val_loss: 0.8157 - val_accuracy: 0.7496\n",
            "Epoch 577/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2649 - accuracy: 0.8888 - val_loss: 0.8072 - val_accuracy: 0.7686\n",
            "Epoch 578/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2657 - accuracy: 0.8878 - val_loss: 0.7974 - val_accuracy: 0.7722\n",
            "Epoch 579/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2655 - accuracy: 0.8894 - val_loss: 0.7885 - val_accuracy: 0.7739\n",
            "Epoch 580/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2654 - accuracy: 0.8887 - val_loss: 0.8073 - val_accuracy: 0.7745\n",
            "Epoch 581/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.8885 - val_loss: 0.7963 - val_accuracy: 0.7768\n",
            "Epoch 582/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8890 - val_loss: 0.8121 - val_accuracy: 0.7460\n",
            "Epoch 583/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2639 - accuracy: 0.8886 - val_loss: 0.7987 - val_accuracy: 0.7625\n",
            "Epoch 584/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2654 - accuracy: 0.8889 - val_loss: 0.8045 - val_accuracy: 0.7525\n",
            "Epoch 585/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2656 - accuracy: 0.8901 - val_loss: 0.7875 - val_accuracy: 0.7673\n",
            "Epoch 586/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2651 - accuracy: 0.8880 - val_loss: 0.7987 - val_accuracy: 0.7798\n",
            "Epoch 587/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2679 - accuracy: 0.8886 - val_loss: 0.8064 - val_accuracy: 0.7698\n",
            "Epoch 588/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2627 - accuracy: 0.8892 - val_loss: 0.8068 - val_accuracy: 0.7823\n",
            "Epoch 589/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.8880 - val_loss: 0.8116 - val_accuracy: 0.7785\n",
            "Epoch 590/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8891 - val_loss: 0.8006 - val_accuracy: 0.7622\n",
            "Epoch 591/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.8900 - val_loss: 0.8104 - val_accuracy: 0.7673\n",
            "Epoch 592/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8876 - val_loss: 0.7932 - val_accuracy: 0.7707\n",
            "Epoch 593/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2652 - accuracy: 0.8886 - val_loss: 0.8136 - val_accuracy: 0.7745\n",
            "Epoch 594/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2684 - accuracy: 0.8863 - val_loss: 0.8009 - val_accuracy: 0.7616\n",
            "Epoch 595/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2655 - accuracy: 0.8900 - val_loss: 0.8059 - val_accuracy: 0.7627\n",
            "Epoch 596/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2650 - accuracy: 0.8900 - val_loss: 0.7920 - val_accuracy: 0.7785\n",
            "Epoch 597/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8902 - val_loss: 0.8060 - val_accuracy: 0.7629\n",
            "Epoch 598/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.8900 - val_loss: 0.8170 - val_accuracy: 0.7559\n",
            "Epoch 599/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2645 - accuracy: 0.8901 - val_loss: 0.8062 - val_accuracy: 0.7686\n",
            "Epoch 600/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8894 - val_loss: 0.8040 - val_accuracy: 0.7844\n",
            "Epoch 601/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8887 - val_loss: 0.8063 - val_accuracy: 0.7625\n",
            "Epoch 602/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8904 - val_loss: 0.7983 - val_accuracy: 0.7671\n",
            "Epoch 603/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.8873 - val_loss: 0.8011 - val_accuracy: 0.7777\n",
            "Epoch 604/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2609 - accuracy: 0.8900 - val_loss: 0.8044 - val_accuracy: 0.7755\n",
            "Epoch 605/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2627 - accuracy: 0.8897 - val_loss: 0.8079 - val_accuracy: 0.7587\n",
            "Epoch 606/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2651 - accuracy: 0.8878 - val_loss: 0.8189 - val_accuracy: 0.7825\n",
            "Epoch 607/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8895 - val_loss: 0.8108 - val_accuracy: 0.7755\n",
            "Epoch 608/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2653 - accuracy: 0.8889 - val_loss: 0.8083 - val_accuracy: 0.7652\n",
            "Epoch 609/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.8899 - val_loss: 0.8210 - val_accuracy: 0.7595\n",
            "Epoch 610/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2644 - accuracy: 0.8888 - val_loss: 0.7995 - val_accuracy: 0.7707\n",
            "Epoch 611/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.8900 - val_loss: 0.8031 - val_accuracy: 0.7665\n",
            "Epoch 612/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.8910 - val_loss: 0.7980 - val_accuracy: 0.7810\n",
            "Epoch 613/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.8905 - val_loss: 0.8295 - val_accuracy: 0.7787\n",
            "Epoch 614/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2644 - accuracy: 0.8900 - val_loss: 0.8139 - val_accuracy: 0.7707\n",
            "Epoch 615/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2645 - accuracy: 0.8882 - val_loss: 0.8209 - val_accuracy: 0.7690\n",
            "Epoch 616/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2623 - accuracy: 0.8907 - val_loss: 0.8288 - val_accuracy: 0.7458\n",
            "Epoch 617/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2629 - accuracy: 0.8920 - val_loss: 0.8194 - val_accuracy: 0.7722\n",
            "Epoch 618/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2636 - accuracy: 0.8910 - val_loss: 0.8188 - val_accuracy: 0.7639\n",
            "Epoch 619/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2660 - accuracy: 0.8863 - val_loss: 0.8050 - val_accuracy: 0.7694\n",
            "Epoch 620/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2706 - accuracy: 0.8876 - val_loss: 0.8102 - val_accuracy: 0.7633\n",
            "Epoch 621/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8910 - val_loss: 0.8158 - val_accuracy: 0.7703\n",
            "Epoch 622/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.8932 - val_loss: 0.8120 - val_accuracy: 0.7717\n",
            "Epoch 623/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2661 - accuracy: 0.8904 - val_loss: 0.8152 - val_accuracy: 0.7703\n",
            "Epoch 624/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2620 - accuracy: 0.8925 - val_loss: 0.8213 - val_accuracy: 0.7815\n",
            "Epoch 625/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2621 - accuracy: 0.8910 - val_loss: 0.8332 - val_accuracy: 0.7532\n",
            "Epoch 626/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2635 - accuracy: 0.8897 - val_loss: 0.8207 - val_accuracy: 0.7694\n",
            "Epoch 627/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.8897 - val_loss: 0.8115 - val_accuracy: 0.7764\n",
            "Epoch 628/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8896 - val_loss: 0.8110 - val_accuracy: 0.7696\n",
            "Epoch 629/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2637 - accuracy: 0.8895 - val_loss: 0.8231 - val_accuracy: 0.7663\n",
            "Epoch 630/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2619 - accuracy: 0.8923 - val_loss: 0.8106 - val_accuracy: 0.7608\n",
            "Epoch 631/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8912 - val_loss: 0.8086 - val_accuracy: 0.7580\n",
            "Epoch 632/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.8909 - val_loss: 0.8172 - val_accuracy: 0.7663\n",
            "Epoch 633/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2634 - accuracy: 0.8890 - val_loss: 0.8320 - val_accuracy: 0.7745\n",
            "Epoch 634/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2644 - accuracy: 0.8916 - val_loss: 0.8203 - val_accuracy: 0.7684\n",
            "Epoch 635/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2609 - accuracy: 0.8921 - val_loss: 0.8182 - val_accuracy: 0.7610\n",
            "Epoch 636/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2621 - accuracy: 0.8905 - val_loss: 0.8308 - val_accuracy: 0.7722\n",
            "Epoch 637/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2613 - accuracy: 0.8912 - val_loss: 0.8199 - val_accuracy: 0.7785\n",
            "Epoch 638/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2622 - accuracy: 0.8882 - val_loss: 0.8146 - val_accuracy: 0.7741\n",
            "Epoch 639/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2658 - accuracy: 0.8897 - val_loss: 0.8197 - val_accuracy: 0.7768\n",
            "Epoch 640/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.8904 - val_loss: 0.8279 - val_accuracy: 0.7473\n",
            "Epoch 641/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.8919 - val_loss: 0.8221 - val_accuracy: 0.7563\n",
            "Epoch 642/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2631 - accuracy: 0.8902 - val_loss: 0.8197 - val_accuracy: 0.7747\n",
            "Epoch 643/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2635 - accuracy: 0.8898 - val_loss: 0.8129 - val_accuracy: 0.7684\n",
            "Epoch 644/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2634 - accuracy: 0.8880 - val_loss: 0.8192 - val_accuracy: 0.7591\n",
            "Epoch 645/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2601 - accuracy: 0.8909 - val_loss: 0.8112 - val_accuracy: 0.7684\n",
            "Epoch 646/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2636 - accuracy: 0.8887 - val_loss: 0.8155 - val_accuracy: 0.7593\n",
            "Epoch 647/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2623 - accuracy: 0.8909 - val_loss: 0.8311 - val_accuracy: 0.7709\n",
            "Epoch 648/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.8918 - val_loss: 0.8337 - val_accuracy: 0.7781\n",
            "Epoch 649/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.8915 - val_loss: 0.8171 - val_accuracy: 0.7665\n",
            "Epoch 650/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2630 - accuracy: 0.8901 - val_loss: 0.8178 - val_accuracy: 0.7821\n",
            "Epoch 651/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.8896 - val_loss: 0.8211 - val_accuracy: 0.7622\n",
            "Epoch 652/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2633 - accuracy: 0.8899 - val_loss: 0.8251 - val_accuracy: 0.7682\n",
            "Epoch 653/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.8904 - val_loss: 0.8177 - val_accuracy: 0.7810\n",
            "Epoch 654/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.8906 - val_loss: 0.8290 - val_accuracy: 0.7559\n",
            "Epoch 655/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2600 - accuracy: 0.8916 - val_loss: 0.8272 - val_accuracy: 0.7663\n",
            "Epoch 656/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2617 - accuracy: 0.8906 - val_loss: 0.8374 - val_accuracy: 0.7625\n",
            "Epoch 657/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.8895 - val_loss: 0.8198 - val_accuracy: 0.7591\n",
            "Epoch 658/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.8922 - val_loss: 0.8213 - val_accuracy: 0.7682\n",
            "Epoch 659/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2612 - accuracy: 0.8905 - val_loss: 0.8274 - val_accuracy: 0.7572\n",
            "Epoch 660/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2628 - accuracy: 0.8889 - val_loss: 0.8339 - val_accuracy: 0.7610\n",
            "Epoch 661/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2587 - accuracy: 0.8921 - val_loss: 0.8292 - val_accuracy: 0.7857\n",
            "Epoch 662/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.8904 - val_loss: 0.8172 - val_accuracy: 0.7627\n",
            "Epoch 663/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.8923 - val_loss: 0.8193 - val_accuracy: 0.7692\n",
            "Epoch 664/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.8903 - val_loss: 0.8224 - val_accuracy: 0.7736\n",
            "Epoch 665/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2605 - accuracy: 0.8909 - val_loss: 0.8241 - val_accuracy: 0.7798\n",
            "Epoch 666/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2605 - accuracy: 0.8916 - val_loss: 0.8416 - val_accuracy: 0.7734\n",
            "Epoch 667/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2617 - accuracy: 0.8918 - val_loss: 0.8454 - val_accuracy: 0.7591\n",
            "Epoch 668/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2599 - accuracy: 0.8899 - val_loss: 0.8353 - val_accuracy: 0.7728\n",
            "Epoch 669/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.8928 - val_loss: 0.8310 - val_accuracy: 0.7580\n",
            "Epoch 670/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2607 - accuracy: 0.8917 - val_loss: 0.8486 - val_accuracy: 0.7673\n",
            "Epoch 671/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2648 - accuracy: 0.8909 - val_loss: 0.8410 - val_accuracy: 0.7669\n",
            "Epoch 672/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2604 - accuracy: 0.8916 - val_loss: 0.8297 - val_accuracy: 0.7587\n",
            "Epoch 673/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.8913 - val_loss: 0.8260 - val_accuracy: 0.7656\n",
            "Epoch 674/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2612 - accuracy: 0.8900 - val_loss: 0.8364 - val_accuracy: 0.7616\n",
            "Epoch 675/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2587 - accuracy: 0.8906 - val_loss: 0.8331 - val_accuracy: 0.7633\n",
            "Epoch 676/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.8918 - val_loss: 0.8301 - val_accuracy: 0.7770\n",
            "Epoch 677/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.8920 - val_loss: 0.8351 - val_accuracy: 0.7804\n",
            "Epoch 678/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2593 - accuracy: 0.8916 - val_loss: 0.8430 - val_accuracy: 0.7599\n",
            "Epoch 679/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2626 - accuracy: 0.8897 - val_loss: 0.8304 - val_accuracy: 0.7726\n",
            "Epoch 680/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2596 - accuracy: 0.8930 - val_loss: 0.8384 - val_accuracy: 0.7658\n",
            "Epoch 681/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2594 - accuracy: 0.8928 - val_loss: 0.8293 - val_accuracy: 0.7656\n",
            "Epoch 682/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.8922 - val_loss: 0.8696 - val_accuracy: 0.7441\n",
            "Epoch 683/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2625 - accuracy: 0.8907 - val_loss: 0.8150 - val_accuracy: 0.7846\n",
            "Epoch 684/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2595 - accuracy: 0.8921 - val_loss: 0.8281 - val_accuracy: 0.7772\n",
            "Epoch 685/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2572 - accuracy: 0.8941 - val_loss: 0.8463 - val_accuracy: 0.7498\n",
            "Epoch 686/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2602 - accuracy: 0.8903 - val_loss: 0.8304 - val_accuracy: 0.7644\n",
            "Epoch 687/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2593 - accuracy: 0.8918 - val_loss: 0.8370 - val_accuracy: 0.7707\n",
            "Epoch 688/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2605 - accuracy: 0.8918 - val_loss: 0.8278 - val_accuracy: 0.7747\n",
            "Epoch 689/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2585 - accuracy: 0.8918 - val_loss: 0.8415 - val_accuracy: 0.7686\n",
            "Epoch 690/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2603 - accuracy: 0.8920 - val_loss: 0.8343 - val_accuracy: 0.7669\n",
            "Epoch 691/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2590 - accuracy: 0.8909 - val_loss: 0.8418 - val_accuracy: 0.7673\n",
            "Epoch 692/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2587 - accuracy: 0.8918 - val_loss: 0.8490 - val_accuracy: 0.7445\n",
            "Epoch 693/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2586 - accuracy: 0.8908 - val_loss: 0.8382 - val_accuracy: 0.7701\n",
            "Epoch 694/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2615 - accuracy: 0.8906 - val_loss: 0.8324 - val_accuracy: 0.7703\n",
            "Epoch 695/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2618 - accuracy: 0.8887 - val_loss: 0.8305 - val_accuracy: 0.7517\n",
            "Epoch 696/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2602 - accuracy: 0.8910 - val_loss: 0.8386 - val_accuracy: 0.7768\n",
            "Epoch 697/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.8914 - val_loss: 0.8334 - val_accuracy: 0.7749\n",
            "Epoch 698/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2564 - accuracy: 0.8944 - val_loss: 0.8319 - val_accuracy: 0.7749\n",
            "Epoch 699/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2615 - accuracy: 0.8924 - val_loss: 0.8332 - val_accuracy: 0.7734\n",
            "Epoch 700/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.8924 - val_loss: 0.8483 - val_accuracy: 0.7743\n",
            "Epoch 701/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2602 - accuracy: 0.8908 - val_loss: 0.8437 - val_accuracy: 0.7764\n",
            "Epoch 702/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.8905 - val_loss: 0.8398 - val_accuracy: 0.7641\n",
            "Epoch 703/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2571 - accuracy: 0.8940 - val_loss: 0.8436 - val_accuracy: 0.7648\n",
            "Epoch 704/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2574 - accuracy: 0.8939 - val_loss: 0.8462 - val_accuracy: 0.7781\n",
            "Epoch 705/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2572 - accuracy: 0.8935 - val_loss: 0.8349 - val_accuracy: 0.7599\n",
            "Epoch 706/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2590 - accuracy: 0.8924 - val_loss: 0.8377 - val_accuracy: 0.7608\n",
            "Epoch 707/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2569 - accuracy: 0.8932 - val_loss: 0.8472 - val_accuracy: 0.7652\n",
            "Epoch 708/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2593 - accuracy: 0.8932 - val_loss: 0.8493 - val_accuracy: 0.7496\n",
            "Epoch 709/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.8925 - val_loss: 0.8397 - val_accuracy: 0.7629\n",
            "Epoch 710/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2598 - accuracy: 0.8917 - val_loss: 0.8325 - val_accuracy: 0.7553\n",
            "Epoch 711/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2608 - accuracy: 0.8921 - val_loss: 0.8386 - val_accuracy: 0.7810\n",
            "Epoch 712/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2580 - accuracy: 0.8926 - val_loss: 0.8545 - val_accuracy: 0.7540\n",
            "Epoch 713/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2558 - accuracy: 0.8928 - val_loss: 0.8462 - val_accuracy: 0.7749\n",
            "Epoch 714/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2594 - accuracy: 0.8903 - val_loss: 0.8367 - val_accuracy: 0.7612\n",
            "Epoch 715/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2560 - accuracy: 0.8928 - val_loss: 0.8551 - val_accuracy: 0.7608\n",
            "Epoch 716/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2589 - accuracy: 0.8931 - val_loss: 0.8313 - val_accuracy: 0.7601\n",
            "Epoch 717/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.8895 - val_loss: 0.8254 - val_accuracy: 0.7713\n",
            "Epoch 718/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2609 - accuracy: 0.8915 - val_loss: 0.8447 - val_accuracy: 0.7711\n",
            "Epoch 719/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.8910 - val_loss: 0.8469 - val_accuracy: 0.7616\n",
            "Epoch 720/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8939 - val_loss: 0.8434 - val_accuracy: 0.7796\n",
            "Epoch 721/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.8921 - val_loss: 0.8304 - val_accuracy: 0.7709\n",
            "Epoch 722/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.8911 - val_loss: 0.8402 - val_accuracy: 0.7627\n",
            "Epoch 723/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2578 - accuracy: 0.8905 - val_loss: 0.8501 - val_accuracy: 0.7739\n",
            "Epoch 724/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2567 - accuracy: 0.8923 - val_loss: 0.8463 - val_accuracy: 0.7720\n",
            "Epoch 725/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2575 - accuracy: 0.8937 - val_loss: 0.8393 - val_accuracy: 0.7726\n",
            "Epoch 726/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2572 - accuracy: 0.8929 - val_loss: 0.8471 - val_accuracy: 0.7646\n",
            "Epoch 727/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2565 - accuracy: 0.8919 - val_loss: 0.8412 - val_accuracy: 0.7726\n",
            "Epoch 728/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2577 - accuracy: 0.8925 - val_loss: 0.8441 - val_accuracy: 0.7720\n",
            "Epoch 729/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2584 - accuracy: 0.8926 - val_loss: 0.8425 - val_accuracy: 0.7741\n",
            "Epoch 730/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2573 - accuracy: 0.8950 - val_loss: 0.8503 - val_accuracy: 0.7684\n",
            "Epoch 731/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8945 - val_loss: 0.8509 - val_accuracy: 0.7540\n",
            "Epoch 732/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2589 - accuracy: 0.8911 - val_loss: 0.8493 - val_accuracy: 0.7656\n",
            "Epoch 733/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2599 - accuracy: 0.8911 - val_loss: 0.8334 - val_accuracy: 0.7635\n",
            "Epoch 734/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2573 - accuracy: 0.8943 - val_loss: 0.8430 - val_accuracy: 0.7677\n",
            "Epoch 735/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2543 - accuracy: 0.8929 - val_loss: 0.8577 - val_accuracy: 0.7747\n",
            "Epoch 736/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2575 - accuracy: 0.8938 - val_loss: 0.8550 - val_accuracy: 0.7679\n",
            "Epoch 737/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2571 - accuracy: 0.8923 - val_loss: 0.8527 - val_accuracy: 0.7669\n",
            "Epoch 738/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2565 - accuracy: 0.8927 - val_loss: 0.8478 - val_accuracy: 0.7736\n",
            "Epoch 739/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2568 - accuracy: 0.8919 - val_loss: 0.8502 - val_accuracy: 0.7703\n",
            "Epoch 740/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2576 - accuracy: 0.8928 - val_loss: 0.8333 - val_accuracy: 0.7734\n",
            "Epoch 741/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2565 - accuracy: 0.8935 - val_loss: 0.8515 - val_accuracy: 0.7741\n",
            "Epoch 742/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2557 - accuracy: 0.8915 - val_loss: 0.8427 - val_accuracy: 0.7732\n",
            "Epoch 743/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2554 - accuracy: 0.8939 - val_loss: 0.8488 - val_accuracy: 0.7614\n",
            "Epoch 744/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2560 - accuracy: 0.8919 - val_loss: 0.8451 - val_accuracy: 0.7652\n",
            "Epoch 745/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2583 - accuracy: 0.8906 - val_loss: 0.8595 - val_accuracy: 0.7635\n",
            "Epoch 746/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2546 - accuracy: 0.8941 - val_loss: 0.8450 - val_accuracy: 0.7561\n",
            "Epoch 747/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.8930 - val_loss: 0.8557 - val_accuracy: 0.7606\n",
            "Epoch 748/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.8960 - val_loss: 0.8467 - val_accuracy: 0.7747\n",
            "Epoch 749/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2544 - accuracy: 0.8945 - val_loss: 0.8598 - val_accuracy: 0.7770\n",
            "Epoch 750/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2559 - accuracy: 0.8926 - val_loss: 0.8458 - val_accuracy: 0.7793\n",
            "Epoch 751/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.8924 - val_loss: 0.8561 - val_accuracy: 0.7728\n",
            "Epoch 752/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2564 - accuracy: 0.8933 - val_loss: 0.8430 - val_accuracy: 0.7656\n",
            "Epoch 753/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2561 - accuracy: 0.8925 - val_loss: 0.8457 - val_accuracy: 0.7652\n",
            "Epoch 754/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2552 - accuracy: 0.8939 - val_loss: 0.8589 - val_accuracy: 0.7631\n",
            "Epoch 755/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2564 - accuracy: 0.8927 - val_loss: 0.8540 - val_accuracy: 0.7688\n",
            "Epoch 756/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2569 - accuracy: 0.8907 - val_loss: 0.8493 - val_accuracy: 0.7762\n",
            "Epoch 757/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2558 - accuracy: 0.8934 - val_loss: 0.8517 - val_accuracy: 0.7506\n",
            "Epoch 758/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2556 - accuracy: 0.8935 - val_loss: 0.8564 - val_accuracy: 0.7656\n",
            "Epoch 759/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2557 - accuracy: 0.8919 - val_loss: 0.8477 - val_accuracy: 0.7631\n",
            "Epoch 760/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.8939 - val_loss: 0.8568 - val_accuracy: 0.7686\n",
            "Epoch 761/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2547 - accuracy: 0.8936 - val_loss: 0.8551 - val_accuracy: 0.7796\n",
            "Epoch 762/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2541 - accuracy: 0.8938 - val_loss: 0.8360 - val_accuracy: 0.7682\n",
            "Epoch 763/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2577 - accuracy: 0.8932 - val_loss: 0.8564 - val_accuracy: 0.7665\n",
            "Epoch 764/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2556 - accuracy: 0.8929 - val_loss: 0.8495 - val_accuracy: 0.7532\n",
            "Epoch 765/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2545 - accuracy: 0.8940 - val_loss: 0.8565 - val_accuracy: 0.7709\n",
            "Epoch 766/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2534 - accuracy: 0.8949 - val_loss: 0.8500 - val_accuracy: 0.7802\n",
            "Epoch 767/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2534 - accuracy: 0.8949 - val_loss: 0.8436 - val_accuracy: 0.7715\n",
            "Epoch 768/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2549 - accuracy: 0.8928 - val_loss: 0.8637 - val_accuracy: 0.7694\n",
            "Epoch 769/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2539 - accuracy: 0.8931 - val_loss: 0.8687 - val_accuracy: 0.7827\n",
            "Epoch 770/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2573 - accuracy: 0.8917 - val_loss: 0.8708 - val_accuracy: 0.7684\n",
            "Epoch 771/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2570 - accuracy: 0.8928 - val_loss: 0.8649 - val_accuracy: 0.7625\n",
            "Epoch 772/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2534 - accuracy: 0.8922 - val_loss: 0.8628 - val_accuracy: 0.7652\n",
            "Epoch 773/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2546 - accuracy: 0.8934 - val_loss: 0.8665 - val_accuracy: 0.7671\n",
            "Epoch 774/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2547 - accuracy: 0.8948 - val_loss: 0.8590 - val_accuracy: 0.7637\n",
            "Epoch 775/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2551 - accuracy: 0.8958 - val_loss: 0.8678 - val_accuracy: 0.7707\n",
            "Epoch 776/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2552 - accuracy: 0.8922 - val_loss: 0.8536 - val_accuracy: 0.7783\n",
            "Epoch 777/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2540 - accuracy: 0.8936 - val_loss: 0.8936 - val_accuracy: 0.7627\n",
            "Epoch 778/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2568 - accuracy: 0.8919 - val_loss: 0.8530 - val_accuracy: 0.7679\n",
            "Epoch 779/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.8933 - val_loss: 0.8711 - val_accuracy: 0.7673\n",
            "Epoch 780/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.8950 - val_loss: 0.8651 - val_accuracy: 0.7675\n",
            "Epoch 781/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2559 - accuracy: 0.8926 - val_loss: 0.8592 - val_accuracy: 0.7777\n",
            "Epoch 782/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2565 - accuracy: 0.8940 - val_loss: 0.8828 - val_accuracy: 0.7348\n",
            "Epoch 783/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2550 - accuracy: 0.8927 - val_loss: 0.8620 - val_accuracy: 0.7612\n",
            "Epoch 784/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2545 - accuracy: 0.8935 - val_loss: 0.8793 - val_accuracy: 0.7656\n",
            "Epoch 785/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2553 - accuracy: 0.8923 - val_loss: 0.8610 - val_accuracy: 0.7587\n",
            "Epoch 786/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2523 - accuracy: 0.8944 - val_loss: 0.8779 - val_accuracy: 0.7705\n",
            "Epoch 787/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2516 - accuracy: 0.8959 - val_loss: 0.8696 - val_accuracy: 0.7819\n",
            "Epoch 788/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.8934 - val_loss: 0.8598 - val_accuracy: 0.7739\n",
            "Epoch 789/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.8934 - val_loss: 0.8833 - val_accuracy: 0.7487\n",
            "Epoch 790/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2546 - accuracy: 0.8930 - val_loss: 0.8657 - val_accuracy: 0.7694\n",
            "Epoch 791/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2539 - accuracy: 0.8951 - val_loss: 0.8634 - val_accuracy: 0.7753\n",
            "Epoch 792/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2535 - accuracy: 0.8953 - val_loss: 0.8534 - val_accuracy: 0.7684\n",
            "Epoch 793/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2565 - accuracy: 0.8929 - val_loss: 0.8754 - val_accuracy: 0.7565\n",
            "Epoch 794/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2502 - accuracy: 0.8951 - val_loss: 0.8882 - val_accuracy: 0.7445\n",
            "Epoch 795/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2524 - accuracy: 0.8957 - val_loss: 0.8603 - val_accuracy: 0.7658\n",
            "Epoch 796/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.8938 - val_loss: 0.8860 - val_accuracy: 0.7519\n",
            "Epoch 797/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2552 - accuracy: 0.8929 - val_loss: 0.8638 - val_accuracy: 0.7728\n",
            "Epoch 798/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2551 - accuracy: 0.8917 - val_loss: 0.8685 - val_accuracy: 0.7707\n",
            "Epoch 799/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2543 - accuracy: 0.8925 - val_loss: 0.8722 - val_accuracy: 0.7658\n",
            "Epoch 800/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.8940 - val_loss: 0.8710 - val_accuracy: 0.7764\n",
            "Epoch 801/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2545 - accuracy: 0.8919 - val_loss: 0.8621 - val_accuracy: 0.7753\n",
            "Epoch 802/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2542 - accuracy: 0.8927 - val_loss: 0.8559 - val_accuracy: 0.7772\n",
            "Epoch 803/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2581 - accuracy: 0.8920 - val_loss: 0.8678 - val_accuracy: 0.7557\n",
            "Epoch 804/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2526 - accuracy: 0.8928 - val_loss: 0.8646 - val_accuracy: 0.7527\n",
            "Epoch 805/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2537 - accuracy: 0.8945 - val_loss: 0.8496 - val_accuracy: 0.7603\n",
            "Epoch 806/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.8961 - val_loss: 0.8707 - val_accuracy: 0.7713\n",
            "Epoch 807/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.8944 - val_loss: 0.8661 - val_accuracy: 0.7646\n",
            "Epoch 808/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.8934 - val_loss: 0.8665 - val_accuracy: 0.7764\n",
            "Epoch 809/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2529 - accuracy: 0.8945 - val_loss: 0.8672 - val_accuracy: 0.7614\n",
            "Epoch 810/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2538 - accuracy: 0.8933 - val_loss: 0.8678 - val_accuracy: 0.7559\n",
            "Epoch 811/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2522 - accuracy: 0.8934 - val_loss: 0.8659 - val_accuracy: 0.7679\n",
            "Epoch 812/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2531 - accuracy: 0.8942 - val_loss: 0.8663 - val_accuracy: 0.7658\n",
            "Epoch 813/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2519 - accuracy: 0.8948 - val_loss: 0.8696 - val_accuracy: 0.7694\n",
            "Epoch 814/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2541 - accuracy: 0.8926 - val_loss: 0.8753 - val_accuracy: 0.7758\n",
            "Epoch 815/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.8946 - val_loss: 0.8633 - val_accuracy: 0.7741\n",
            "Epoch 816/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.8938 - val_loss: 0.8656 - val_accuracy: 0.7652\n",
            "Epoch 817/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2543 - accuracy: 0.8929 - val_loss: 0.8940 - val_accuracy: 0.7397\n",
            "Epoch 818/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2508 - accuracy: 0.8954 - val_loss: 0.8827 - val_accuracy: 0.7608\n",
            "Epoch 819/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.8944 - val_loss: 0.8944 - val_accuracy: 0.7513\n",
            "Epoch 820/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2523 - accuracy: 0.8938 - val_loss: 0.8758 - val_accuracy: 0.7614\n",
            "Epoch 821/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2565 - accuracy: 0.8938 - val_loss: 0.8631 - val_accuracy: 0.7625\n",
            "Epoch 822/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2545 - accuracy: 0.8925 - val_loss: 0.8711 - val_accuracy: 0.7563\n",
            "Epoch 823/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2515 - accuracy: 0.8937 - val_loss: 0.8844 - val_accuracy: 0.7418\n",
            "Epoch 824/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2496 - accuracy: 0.8963 - val_loss: 0.8689 - val_accuracy: 0.7635\n",
            "Epoch 825/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2543 - accuracy: 0.8945 - val_loss: 0.8796 - val_accuracy: 0.7703\n",
            "Epoch 826/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.8937 - val_loss: 0.8777 - val_accuracy: 0.7580\n",
            "Epoch 827/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.8931 - val_loss: 0.8678 - val_accuracy: 0.7570\n",
            "Epoch 828/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.8967 - val_loss: 0.8670 - val_accuracy: 0.7696\n",
            "Epoch 829/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.8957 - val_loss: 0.8633 - val_accuracy: 0.7555\n",
            "Epoch 830/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2532 - accuracy: 0.8942 - val_loss: 0.8775 - val_accuracy: 0.7625\n",
            "Epoch 831/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2513 - accuracy: 0.8960 - val_loss: 0.8644 - val_accuracy: 0.7692\n",
            "Epoch 832/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2532 - accuracy: 0.8925 - val_loss: 0.8811 - val_accuracy: 0.7521\n",
            "Epoch 833/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2503 - accuracy: 0.8947 - val_loss: 0.8826 - val_accuracy: 0.7561\n",
            "Epoch 834/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2513 - accuracy: 0.8945 - val_loss: 0.8778 - val_accuracy: 0.7641\n",
            "Epoch 835/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.8967 - val_loss: 0.8832 - val_accuracy: 0.7631\n",
            "Epoch 836/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.8948 - val_loss: 0.8774 - val_accuracy: 0.7715\n",
            "Epoch 837/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2536 - accuracy: 0.8956 - val_loss: 0.8636 - val_accuracy: 0.7650\n",
            "Epoch 838/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2510 - accuracy: 0.8948 - val_loss: 0.8842 - val_accuracy: 0.7610\n",
            "Epoch 839/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2516 - accuracy: 0.8944 - val_loss: 0.8872 - val_accuracy: 0.7652\n",
            "Epoch 840/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2500 - accuracy: 0.8943 - val_loss: 0.8744 - val_accuracy: 0.7635\n",
            "Epoch 841/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2511 - accuracy: 0.8973 - val_loss: 0.8854 - val_accuracy: 0.7652\n",
            "Epoch 842/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2525 - accuracy: 0.8934 - val_loss: 0.8790 - val_accuracy: 0.7544\n",
            "Epoch 843/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2502 - accuracy: 0.8969 - val_loss: 0.8777 - val_accuracy: 0.7542\n",
            "Epoch 844/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2499 - accuracy: 0.8952 - val_loss: 0.8761 - val_accuracy: 0.7513\n",
            "Epoch 845/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.8976 - val_loss: 0.8795 - val_accuracy: 0.7572\n",
            "Epoch 846/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2531 - accuracy: 0.8929 - val_loss: 0.8750 - val_accuracy: 0.7726\n",
            "Epoch 847/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2521 - accuracy: 0.8956 - val_loss: 0.8865 - val_accuracy: 0.7553\n",
            "Epoch 848/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2535 - accuracy: 0.8933 - val_loss: 0.8833 - val_accuracy: 0.7578\n",
            "Epoch 849/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.8957 - val_loss: 0.8881 - val_accuracy: 0.7722\n",
            "Epoch 850/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2513 - accuracy: 0.8955 - val_loss: 0.8818 - val_accuracy: 0.7665\n",
            "Epoch 851/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.8944 - val_loss: 0.8797 - val_accuracy: 0.7739\n",
            "Epoch 852/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2504 - accuracy: 0.8959 - val_loss: 0.8859 - val_accuracy: 0.7601\n",
            "Epoch 853/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2532 - accuracy: 0.8962 - val_loss: 0.8794 - val_accuracy: 0.7576\n",
            "Epoch 854/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2493 - accuracy: 0.8953 - val_loss: 0.8908 - val_accuracy: 0.7523\n",
            "Epoch 855/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2492 - accuracy: 0.8956 - val_loss: 0.8874 - val_accuracy: 0.7618\n",
            "Epoch 856/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.8975 - val_loss: 0.8834 - val_accuracy: 0.7646\n",
            "Epoch 857/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2514 - accuracy: 0.8946 - val_loss: 0.8808 - val_accuracy: 0.7728\n",
            "Epoch 858/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2526 - accuracy: 0.8938 - val_loss: 0.8863 - val_accuracy: 0.7701\n",
            "Epoch 859/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2487 - accuracy: 0.8973 - val_loss: 0.8859 - val_accuracy: 0.7523\n",
            "Epoch 860/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.8944 - val_loss: 0.8872 - val_accuracy: 0.7622\n",
            "Epoch 861/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2508 - accuracy: 0.8927 - val_loss: 0.8915 - val_accuracy: 0.7606\n",
            "Epoch 862/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.8963 - val_loss: 0.9011 - val_accuracy: 0.7608\n",
            "Epoch 863/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2504 - accuracy: 0.8938 - val_loss: 0.8910 - val_accuracy: 0.7701\n",
            "Epoch 864/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2479 - accuracy: 0.8955 - val_loss: 0.8932 - val_accuracy: 0.7652\n",
            "Epoch 865/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2489 - accuracy: 0.8931 - val_loss: 0.8871 - val_accuracy: 0.7565\n",
            "Epoch 866/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.8965 - val_loss: 0.9007 - val_accuracy: 0.7538\n",
            "Epoch 867/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2517 - accuracy: 0.8934 - val_loss: 0.8889 - val_accuracy: 0.7667\n",
            "Epoch 868/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2476 - accuracy: 0.8978 - val_loss: 0.8838 - val_accuracy: 0.7734\n",
            "Epoch 869/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2505 - accuracy: 0.8948 - val_loss: 0.8846 - val_accuracy: 0.7741\n",
            "Epoch 870/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2488 - accuracy: 0.8964 - val_loss: 0.9028 - val_accuracy: 0.7753\n",
            "Epoch 871/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2512 - accuracy: 0.8950 - val_loss: 0.8836 - val_accuracy: 0.7741\n",
            "Epoch 872/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2502 - accuracy: 0.8934 - val_loss: 0.8929 - val_accuracy: 0.7608\n",
            "Epoch 873/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2500 - accuracy: 0.8966 - val_loss: 0.8834 - val_accuracy: 0.7652\n",
            "Epoch 874/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2519 - accuracy: 0.8960 - val_loss: 0.8909 - val_accuracy: 0.7589\n",
            "Epoch 875/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2482 - accuracy: 0.8961 - val_loss: 0.9122 - val_accuracy: 0.7633\n",
            "Epoch 876/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2517 - accuracy: 0.8948 - val_loss: 0.8875 - val_accuracy: 0.7671\n",
            "Epoch 877/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2471 - accuracy: 0.8983 - val_loss: 0.8960 - val_accuracy: 0.7483\n",
            "Epoch 878/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2529 - accuracy: 0.8926 - val_loss: 0.8850 - val_accuracy: 0.7656\n",
            "Epoch 879/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.8949 - val_loss: 0.9018 - val_accuracy: 0.7760\n",
            "Epoch 880/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2497 - accuracy: 0.8967 - val_loss: 0.8800 - val_accuracy: 0.7688\n",
            "Epoch 881/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2469 - accuracy: 0.8984 - val_loss: 0.8864 - val_accuracy: 0.7747\n",
            "Epoch 882/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2504 - accuracy: 0.8953 - val_loss: 0.8866 - val_accuracy: 0.7580\n",
            "Epoch 883/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2528 - accuracy: 0.8952 - val_loss: 0.9148 - val_accuracy: 0.7568\n",
            "Epoch 884/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2494 - accuracy: 0.8951 - val_loss: 0.8860 - val_accuracy: 0.7631\n",
            "Epoch 885/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.8947 - val_loss: 0.8998 - val_accuracy: 0.7538\n",
            "Epoch 886/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.8988 - val_loss: 0.8997 - val_accuracy: 0.7462\n",
            "Epoch 887/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2502 - accuracy: 0.8949 - val_loss: 0.8859 - val_accuracy: 0.7660\n",
            "Epoch 888/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2507 - accuracy: 0.8956 - val_loss: 0.8957 - val_accuracy: 0.7732\n",
            "Epoch 889/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2476 - accuracy: 0.8955 - val_loss: 0.8961 - val_accuracy: 0.7492\n",
            "Epoch 890/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2483 - accuracy: 0.8965 - val_loss: 0.8846 - val_accuracy: 0.7589\n",
            "Epoch 891/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2476 - accuracy: 0.8978 - val_loss: 0.8926 - val_accuracy: 0.7698\n",
            "Epoch 892/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2500 - accuracy: 0.8957 - val_loss: 0.8952 - val_accuracy: 0.7570\n",
            "Epoch 893/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2483 - accuracy: 0.8964 - val_loss: 0.9018 - val_accuracy: 0.7652\n",
            "Epoch 894/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.8965 - val_loss: 0.8919 - val_accuracy: 0.7722\n",
            "Epoch 895/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.8956 - val_loss: 0.8973 - val_accuracy: 0.7616\n",
            "Epoch 896/1000\n",
            "592/592 [==============================] - 1s 3ms/step - loss: 0.2490 - accuracy: 0.8951 - val_loss: 0.9028 - val_accuracy: 0.7563\n",
            "Epoch 897/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2464 - accuracy: 0.8979 - val_loss: 0.9032 - val_accuracy: 0.7760\n",
            "Epoch 898/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2489 - accuracy: 0.8937 - val_loss: 0.9018 - val_accuracy: 0.7597\n",
            "Epoch 899/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2500 - accuracy: 0.8958 - val_loss: 0.8875 - val_accuracy: 0.7665\n",
            "Epoch 900/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2466 - accuracy: 0.8987 - val_loss: 0.9264 - val_accuracy: 0.7428\n",
            "Epoch 901/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2491 - accuracy: 0.8950 - val_loss: 0.9132 - val_accuracy: 0.7627\n",
            "Epoch 902/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2489 - accuracy: 0.8970 - val_loss: 0.9066 - val_accuracy: 0.7578\n",
            "Epoch 903/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2477 - accuracy: 0.8951 - val_loss: 0.9108 - val_accuracy: 0.7658\n",
            "Epoch 904/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2496 - accuracy: 0.8966 - val_loss: 0.8977 - val_accuracy: 0.7582\n",
            "Epoch 905/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2492 - accuracy: 0.8973 - val_loss: 0.9069 - val_accuracy: 0.7620\n",
            "Epoch 906/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2478 - accuracy: 0.8967 - val_loss: 0.9301 - val_accuracy: 0.7439\n",
            "Epoch 907/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2499 - accuracy: 0.8958 - val_loss: 0.9082 - val_accuracy: 0.7696\n",
            "Epoch 908/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.8958 - val_loss: 0.9063 - val_accuracy: 0.7500\n",
            "Epoch 909/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2480 - accuracy: 0.8960 - val_loss: 0.9076 - val_accuracy: 0.7599\n",
            "Epoch 910/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2460 - accuracy: 0.8974 - val_loss: 0.8964 - val_accuracy: 0.7584\n",
            "Epoch 911/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2487 - accuracy: 0.8956 - val_loss: 0.9055 - val_accuracy: 0.7688\n",
            "Epoch 912/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.8971 - val_loss: 0.8980 - val_accuracy: 0.7553\n",
            "Epoch 913/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2467 - accuracy: 0.8976 - val_loss: 0.9137 - val_accuracy: 0.7483\n",
            "Epoch 914/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.8975 - val_loss: 0.9055 - val_accuracy: 0.7654\n",
            "Epoch 915/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2517 - accuracy: 0.8960 - val_loss: 0.9332 - val_accuracy: 0.7420\n",
            "Epoch 916/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2480 - accuracy: 0.8960 - val_loss: 0.9099 - val_accuracy: 0.7513\n",
            "Epoch 917/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.8957 - val_loss: 0.8986 - val_accuracy: 0.7606\n",
            "Epoch 918/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.8950 - val_loss: 0.9054 - val_accuracy: 0.7563\n",
            "Epoch 919/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2484 - accuracy: 0.8957 - val_loss: 0.9049 - val_accuracy: 0.7582\n",
            "Epoch 920/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2493 - accuracy: 0.8958 - val_loss: 0.8976 - val_accuracy: 0.7688\n",
            "Epoch 921/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2484 - accuracy: 0.8966 - val_loss: 0.8984 - val_accuracy: 0.7675\n",
            "Epoch 922/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2468 - accuracy: 0.8958 - val_loss: 0.9091 - val_accuracy: 0.7631\n",
            "Epoch 923/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2473 - accuracy: 0.8969 - val_loss: 0.9114 - val_accuracy: 0.7584\n",
            "Epoch 924/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2477 - accuracy: 0.8970 - val_loss: 0.8979 - val_accuracy: 0.7540\n",
            "Epoch 925/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2483 - accuracy: 0.8956 - val_loss: 0.9024 - val_accuracy: 0.7728\n",
            "Epoch 926/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2469 - accuracy: 0.8950 - val_loss: 0.9051 - val_accuracy: 0.7709\n",
            "Epoch 927/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2462 - accuracy: 0.8971 - val_loss: 0.9048 - val_accuracy: 0.7580\n",
            "Epoch 928/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2471 - accuracy: 0.8971 - val_loss: 0.9109 - val_accuracy: 0.7597\n",
            "Epoch 929/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2478 - accuracy: 0.8962 - val_loss: 0.9100 - val_accuracy: 0.7557\n",
            "Epoch 930/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2464 - accuracy: 0.8970 - val_loss: 0.9093 - val_accuracy: 0.7665\n",
            "Epoch 931/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2468 - accuracy: 0.8973 - val_loss: 0.9041 - val_accuracy: 0.7648\n",
            "Epoch 932/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2468 - accuracy: 0.8966 - val_loss: 0.9104 - val_accuracy: 0.7593\n",
            "Epoch 933/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2482 - accuracy: 0.8956 - val_loss: 0.9051 - val_accuracy: 0.7500\n",
            "Epoch 934/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2462 - accuracy: 0.8994 - val_loss: 0.9322 - val_accuracy: 0.7424\n",
            "Epoch 935/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2469 - accuracy: 0.8957 - val_loss: 0.9093 - val_accuracy: 0.7568\n",
            "Epoch 936/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2457 - accuracy: 0.8978 - val_loss: 0.9114 - val_accuracy: 0.7673\n",
            "Epoch 937/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2462 - accuracy: 0.8955 - val_loss: 0.9068 - val_accuracy: 0.7656\n",
            "Epoch 938/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.8974 - val_loss: 0.9164 - val_accuracy: 0.7494\n",
            "Epoch 939/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2481 - accuracy: 0.8967 - val_loss: 0.9031 - val_accuracy: 0.7589\n",
            "Epoch 940/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2479 - accuracy: 0.8955 - val_loss: 0.9107 - val_accuracy: 0.7582\n",
            "Epoch 941/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2473 - accuracy: 0.8980 - val_loss: 0.9149 - val_accuracy: 0.7399\n",
            "Epoch 942/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2459 - accuracy: 0.8974 - val_loss: 0.9112 - val_accuracy: 0.7622\n",
            "Epoch 943/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2528 - accuracy: 0.8944 - val_loss: 0.9130 - val_accuracy: 0.7724\n",
            "Epoch 944/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.8957 - val_loss: 0.9042 - val_accuracy: 0.7644\n",
            "Epoch 945/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2445 - accuracy: 0.8979 - val_loss: 0.9086 - val_accuracy: 0.7777\n",
            "Epoch 946/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2472 - accuracy: 0.8949 - val_loss: 0.9098 - val_accuracy: 0.7540\n",
            "Epoch 947/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2450 - accuracy: 0.8974 - val_loss: 0.9338 - val_accuracy: 0.7405\n",
            "Epoch 948/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8952 - val_loss: 0.9267 - val_accuracy: 0.7840\n",
            "Epoch 949/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2485 - accuracy: 0.8955 - val_loss: 0.9155 - val_accuracy: 0.7663\n",
            "Epoch 950/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2452 - accuracy: 0.8968 - val_loss: 0.9114 - val_accuracy: 0.7559\n",
            "Epoch 951/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2446 - accuracy: 0.8970 - val_loss: 0.9103 - val_accuracy: 0.7692\n",
            "Epoch 952/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2451 - accuracy: 0.8974 - val_loss: 0.9144 - val_accuracy: 0.7582\n",
            "Epoch 953/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8961 - val_loss: 0.9176 - val_accuracy: 0.7546\n",
            "Epoch 954/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2486 - accuracy: 0.8961 - val_loss: 0.9161 - val_accuracy: 0.7582\n",
            "Epoch 955/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.8967 - val_loss: 0.9133 - val_accuracy: 0.7532\n",
            "Epoch 956/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2475 - accuracy: 0.8967 - val_loss: 0.9171 - val_accuracy: 0.7568\n",
            "Epoch 957/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2458 - accuracy: 0.8959 - val_loss: 0.9100 - val_accuracy: 0.7679\n",
            "Epoch 958/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2456 - accuracy: 0.8984 - val_loss: 0.9156 - val_accuracy: 0.7637\n",
            "Epoch 959/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2456 - accuracy: 0.8987 - val_loss: 0.9148 - val_accuracy: 0.7559\n",
            "Epoch 960/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2455 - accuracy: 0.8967 - val_loss: 0.9127 - val_accuracy: 0.7658\n",
            "Epoch 961/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2451 - accuracy: 0.8971 - val_loss: 0.9140 - val_accuracy: 0.7684\n",
            "Epoch 962/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2440 - accuracy: 0.8983 - val_loss: 0.9045 - val_accuracy: 0.7717\n",
            "Epoch 963/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8985 - val_loss: 0.9118 - val_accuracy: 0.7532\n",
            "Epoch 964/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2467 - accuracy: 0.8953 - val_loss: 0.9124 - val_accuracy: 0.7580\n",
            "Epoch 965/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.8992 - val_loss: 0.9320 - val_accuracy: 0.7574\n",
            "Epoch 966/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2466 - accuracy: 0.8993 - val_loss: 0.9166 - val_accuracy: 0.7802\n",
            "Epoch 967/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2443 - accuracy: 0.8976 - val_loss: 0.9333 - val_accuracy: 0.7481\n",
            "Epoch 968/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.8984 - val_loss: 0.9329 - val_accuracy: 0.7496\n",
            "Epoch 969/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2457 - accuracy: 0.8993 - val_loss: 0.9350 - val_accuracy: 0.7485\n",
            "Epoch 970/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.8961 - val_loss: 0.9216 - val_accuracy: 0.7576\n",
            "Epoch 971/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2450 - accuracy: 0.8960 - val_loss: 0.9350 - val_accuracy: 0.7587\n",
            "Epoch 972/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2477 - accuracy: 0.8960 - val_loss: 0.9257 - val_accuracy: 0.7663\n",
            "Epoch 973/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2458 - accuracy: 0.8963 - val_loss: 0.9336 - val_accuracy: 0.7409\n",
            "Epoch 974/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2460 - accuracy: 0.8980 - val_loss: 0.9251 - val_accuracy: 0.7549\n",
            "Epoch 975/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2446 - accuracy: 0.8982 - val_loss: 0.9130 - val_accuracy: 0.7650\n",
            "Epoch 976/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2428 - accuracy: 0.9004 - val_loss: 0.9418 - val_accuracy: 0.7753\n",
            "Epoch 977/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2454 - accuracy: 0.8973 - val_loss: 0.9172 - val_accuracy: 0.7542\n",
            "Epoch 978/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.8988 - val_loss: 0.9228 - val_accuracy: 0.7534\n",
            "Epoch 979/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2450 - accuracy: 0.9001 - val_loss: 0.9258 - val_accuracy: 0.7614\n",
            "Epoch 980/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2433 - accuracy: 0.9003 - val_loss: 0.9337 - val_accuracy: 0.7698\n",
            "Epoch 981/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2466 - accuracy: 0.8961 - val_loss: 0.9267 - val_accuracy: 0.7601\n",
            "Epoch 982/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.8981 - val_loss: 0.9128 - val_accuracy: 0.7671\n",
            "Epoch 983/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2448 - accuracy: 0.8990 - val_loss: 0.9395 - val_accuracy: 0.7502\n",
            "Epoch 984/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2426 - accuracy: 0.8988 - val_loss: 0.9237 - val_accuracy: 0.7734\n",
            "Epoch 985/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2435 - accuracy: 0.8982 - val_loss: 0.9371 - val_accuracy: 0.7587\n",
            "Epoch 986/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2452 - accuracy: 0.8982 - val_loss: 0.9250 - val_accuracy: 0.7530\n",
            "Epoch 987/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2453 - accuracy: 0.8984 - val_loss: 0.9250 - val_accuracy: 0.7511\n",
            "Epoch 988/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2457 - accuracy: 0.8966 - val_loss: 0.9331 - val_accuracy: 0.7523\n",
            "Epoch 989/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2450 - accuracy: 0.8986 - val_loss: 0.9282 - val_accuracy: 0.7639\n",
            "Epoch 990/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2434 - accuracy: 0.8972 - val_loss: 0.9330 - val_accuracy: 0.7521\n",
            "Epoch 991/1000\n",
            "592/592 [==============================] - 2s 4ms/step - loss: 0.2439 - accuracy: 0.8983 - val_loss: 0.9232 - val_accuracy: 0.7730\n",
            "Epoch 992/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2454 - accuracy: 0.8966 - val_loss: 0.9273 - val_accuracy: 0.7658\n",
            "Epoch 993/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2424 - accuracy: 0.8993 - val_loss: 0.9149 - val_accuracy: 0.7705\n",
            "Epoch 994/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2444 - accuracy: 0.8985 - val_loss: 0.9438 - val_accuracy: 0.7521\n",
            "Epoch 995/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2437 - accuracy: 0.8980 - val_loss: 0.9275 - val_accuracy: 0.7595\n",
            "Epoch 996/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2427 - accuracy: 0.8976 - val_loss: 0.9311 - val_accuracy: 0.7616\n",
            "Epoch 997/1000\n",
            "592/592 [==============================] - 1s 2ms/step - loss: 0.2461 - accuracy: 0.8961 - val_loss: 0.9246 - val_accuracy: 0.7686\n",
            "Epoch 998/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.8976 - val_loss: 0.9355 - val_accuracy: 0.7622\n",
            "Epoch 999/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2458 - accuracy: 0.8988 - val_loss: 0.9392 - val_accuracy: 0.7441\n",
            "Epoch 1000/1000\n",
            "592/592 [==============================] - 2s 3ms/step - loss: 0.2456 - accuracy: 0.8969 - val_loss: 0.9370 - val_accuracy: 0.7492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "# Learning curve(Loss)\n",
        "# let's see the training and validation loss by epoch\n",
        "\n",
        "# loss\n",
        "loss_values = history_dict['loss'] # you can change this\n",
        "val_loss_values = history_dict['val_loss'] # you can also change this\n",
        "\n",
        "# range of X (no. of epochs)\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# plot\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'orange', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "mVHRH3u8KPzA",
        "outputId": "d2266bb0-a117-4fc4-881c-1fa92bfd7a36"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning curve(accuracy)\n",
        "# let's see the training and validation accuracy by epoch\n",
        "\n",
        "# accuracy\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# range of X (no. of epochs)\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# plot\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "# orange is for \"orange\"\n",
        "plt.plot(epochs, val_acc, 'orange', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# this is the max value - should correspond to\n",
        "# the HIGHEST train accuracy\n",
        "np.max(val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "fQxoHLyqMOKv",
        "outputId": "6d349539-5252-4c3f-ed20-6d2af538acc2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.822212815284729"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# see how these are numbers between 0 and 1?\n",
        "model.predict(X) # prob of successes (survival)\n",
        "np.round(model.predict(X),0) # 1 and 0 (survival or not)\n",
        "Y # 1 and 0 (survival or not)\n",
        "\n",
        "# so we need to round to a whole number (0 or 1),\n",
        "# or the confusion matrix won't work!\n",
        "preds = np.round(model.predict(X),0)\n",
        "\n",
        "# confusion matrix\n",
        "print(confusion_matrix(Y, preds)) # order matters! (actual, predicted)\n",
        "\n",
        "## array([[490,  59],   ([[TN, FP],\n",
        "##       [105, 235]])     [Fn, TP]])\n",
        "\n",
        "print(classification_report(Y, preds))\n",
        "##               precision    recall  f1-score   support\n",
        "##\n",
        "##            0       0.82      0.89      0.86       549\n",
        "##            1       0.80      0.69      0.74       340\n",
        "##\n",
        "##     accuracy                           0.82       889\n",
        "##    macro avg       0.81      0.79      0.80       889\n",
        "## weighted avg       0.81      0.82      0.81       889"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA3XFqfoMdn2",
        "outputId": "2497f582-e950-4237-ddf3-823abc90c29f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "926/926 [==============================] - 2s 2ms/step\n",
            "926/926 [==============================] - 3s 3ms/step\n",
            "926/926 [==============================] - 2s 2ms/step\n",
            "[[16016  6980]\n",
            " [ 4301  2304]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.70      0.74     22996\n",
            "           1       0.25      0.35      0.29      6605\n",
            "\n",
            "    accuracy                           0.62     29601\n",
            "   macro avg       0.52      0.52      0.51     29601\n",
            "weighted avg       0.67      0.62      0.64     29601\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo en Google Drive\n",
        "model.save('/content/drive/My Drive/riesgo_credito.keras')"
      ],
      "metadata": {
        "id": "3uPot_npNepw"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}